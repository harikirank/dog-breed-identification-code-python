{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqCU4JHlvkCf"
   },
   "source": [
    "# Note, here we are not showing any baseline model metrics since the accuracy is same for all the baseline models which is 1.09%. The baseline model is included in efficientnet ipynb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-HsR_mXVKVN",
    "outputId": "f909c399-708a-40ca-c343-2674d9089c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-29T18:19:30.109880Z",
     "iopub.status.busy": "2023-04-29T18:19:30.109348Z",
     "iopub.status.idle": "2023-04-29T18:19:30.139110Z",
     "shell.execute_reply": "2023-04-29T18:19:30.137026Z",
     "shell.execute_reply.started": "2023-04-29T18:19:30.109834Z"
    },
    "id": "ALDiBKEUSdzC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tq\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "from PIL import ImageFile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score, classification_report, precision_recall_fscore_support, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import sys\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torchvision import datasets, transforms, models\n",
    "import pprint\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:14:51.326765Z",
     "iopub.status.busy": "2023-04-29T18:14:51.325770Z",
     "iopub.status.idle": "2023-04-29T18:14:51.339703Z",
     "shell.execute_reply": "2023-04-29T18:14:51.337419Z",
     "shell.execute_reply.started": "2023-04-29T18:14:51.326710Z"
    },
    "id": "AJzLYJgHSdzE"
   },
   "outputs": [],
   "source": [
    "def path_given_id(id, test=False):\n",
    "    \"\"\"\n",
    "    Returns the full path to the image given the id of the image.\n",
    "    Parameters:\n",
    "        - id: The id of the image.\n",
    "        - test: If True returns the relative path from the test folder. Otherwise, returns the relative path to the image from the training folder.\n",
    "    Returns:\n",
    "        - The full relative path to the image with the give in id.\n",
    "    \"\"\"\n",
    "    return IMAGES_PATH + ('train/' if not test else 'test/') + str(id) + '.jpg'\n",
    "\n",
    "def get_img_array(id, test=False):\n",
    "    \"\"\"\n",
    "    Loads the image from the given id, convert the image to a numpy array and return the numpy array.\n",
    "    Parameters:\n",
    "        - id: The id of the image.\n",
    "        - test: If True, loads the image from the test folder. If False,loads the image from the train folder.\n",
    "    Returns:\n",
    "        - The image with the give id as a numpy array.\n",
    "    \"\"\"\n",
    "    img = load_img(path_given_id(id, test), target_size=(224, 224))\n",
    "    return img_to_array(img)\n",
    "\n",
    "# preprocess_input(np.expand_dims(get_image_array(id, test), axis=0)) will convert the image into 1,224,224,3 to give to predict.\n",
    "def process_image(id, test=False):\n",
    "    return preprocess_input(np.expand_dims(get_img_array(id, test), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:15:16.014562Z",
     "iopub.status.busy": "2023-04-29T18:15:16.014136Z",
     "iopub.status.idle": "2023-04-29T18:15:16.911182Z",
     "shell.execute_reply": "2023-04-29T18:15:16.909861Z",
     "shell.execute_reply.started": "2023-04-29T18:15:16.014526Z"
    },
    "id": "CuBwqaKBSdzE"
   },
   "outputs": [],
   "source": [
    "IMAGES_PATH = '/content/drive/MyDrive/dog_breed_identification_files/'\n",
    "\n",
    "labels = pd.read_csv(IMAGES_PATH +'labels.csv')\n",
    "labelnames = pd.read_csv(IMAGES_PATH  + 'sample_submission.csv').keys()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:15:25.442332Z",
     "iopub.status.busy": "2023-04-29T18:15:25.441854Z",
     "iopub.status.idle": "2023-04-29T18:15:25.560865Z",
     "shell.execute_reply": "2023-04-29T18:15:25.559125Z",
     "shell.execute_reply.started": "2023-04-29T18:15:25.442288Z"
    },
    "id": "9Epw2mxkSdzE"
   },
   "outputs": [],
   "source": [
    "codes = range(len(labelnames))\n",
    "breed_to_code = dict(zip(labelnames, codes))\n",
    "code_to_breed = dict(zip(codes, labelnames))\n",
    "\n",
    "labels['target'] =  [breed_to_code[x] for x in labels.breed]\n",
    "labels['rank'] = labels.groupby('breed').rank()['id']\n",
    "labels_pivot = labels.pivot('id', 'breed', 'target').reset_index().fillna(0)\n",
    "\n",
    "training_data = labels_pivot.sample(frac=0.85)\n",
    "validation_data = labels_pivot[~labels_pivot['id'].isin(training_data['id'])]\n",
    "testing_data = training_data.sample(frac=0.25)\n",
    "training_data = training_data[~training_data['id'].isin(testing_data['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:17:09.856120Z",
     "iopub.status.busy": "2023-04-29T18:17:09.854385Z",
     "iopub.status.idle": "2023-04-29T18:17:09.868192Z",
     "shell.execute_reply": "2023-04-29T18:17:09.865922Z",
     "shell.execute_reply.started": "2023-04-29T18:17:09.856046Z"
    },
    "id": "-Kg9fqC2SdzE"
   },
   "outputs": [],
   "source": [
    "img_transform = {\n",
    "    'valid':transforms.Compose([\n",
    "        transforms.Resize(size = 224, interpolation=InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(size = 224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'train':transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size = 224),\n",
    "        transforms.RandomRotation(degrees = 30),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),  \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  \n",
    "    ]),\n",
    "    'test':transforms.Compose([\n",
    "        transforms.Resize(size = 224, interpolation=InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(size = 224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:17:31.137386Z",
     "iopub.status.busy": "2023-04-29T18:17:31.136885Z",
     "iopub.status.idle": "2023-04-29T18:17:31.149925Z",
     "shell.execute_reply": "2023-04-29T18:17:31.148282Z",
     "shell.execute_reply.started": "2023-04-29T18:17:31.137345Z"
    },
    "id": "s-Ow4JJ9SdzF"
   },
   "outputs": [],
   "source": [
    "class DogDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Create a dataset for pytorch batch loading. This is to load few images into memory at a time instead of all the images at once.\n",
    "    Extends from torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, images_directory, labels, transform):\n",
    "        \"\"\"\n",
    "        Constructor initialization.\n",
    "        Params:\n",
    "            - images_directory: The directory where the images are stored.\n",
    "            - labels: The image labels\n",
    "            - transform: The transformations to perform on the data.\n",
    "        \"\"\"\n",
    "        self.images_directory = images_directory\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.labels is not None:\n",
    "            image_name = f'{self.labels[\"id\"].iloc[index]}.jpg'\n",
    "            full_image_name = self.images_directory + image_name\n",
    "            \n",
    "            final_image = Image.open(full_image_name)\n",
    "            label = self.labels.iloc[index, 1:].astype('float').to_numpy()\n",
    "            label = np.argmax(label)\n",
    "            \n",
    "            if self.transform:\n",
    "                final_image = self.transform(final_image)\n",
    "            \n",
    "            return [final_image, label]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:17:38.099448Z",
     "iopub.status.busy": "2023-04-29T18:17:38.098926Z",
     "iopub.status.idle": "2023-04-29T18:17:38.110228Z",
     "shell.execute_reply": "2023-04-29T18:17:38.108837Z",
     "shell.execute_reply.started": "2023-04-29T18:17:38.099401Z"
    },
    "id": "2bMplIGOSdzF"
   },
   "outputs": [],
   "source": [
    "num_workers = 4\n",
    "batch_size = 100\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "train_img = DogDataset(IMAGES_PATH + 'train/', training_data, transform = img_transform['train'])\n",
    "valid_img = DogDataset(IMAGES_PATH + 'train/', validation_data, transform = img_transform['valid'])\n",
    "test_img = DogDataset(IMAGES_PATH + 'train/', testing_data, transform = img_transform['test'])\n",
    "\n",
    "\n",
    "dataloaders={\n",
    "    'train':torch.utils.data.DataLoader(train_img, batch_size, num_workers = num_workers, shuffle=True),\n",
    "    'valid':torch.utils.data.DataLoader(valid_img, batch_size, num_workers = num_workers, shuffle=False),\n",
    "    'test':torch.utils.data.DataLoader(test_img, batch_size, num_workers = num_workers, shuffle=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-29T18:25:26.585063Z",
     "iopub.status.busy": "2023-04-29T18:25:26.584640Z",
     "iopub.status.idle": "2023-04-29T18:25:27.217468Z",
     "shell.execute_reply": "2023-04-29T18:25:27.216283Z",
     "shell.execute_reply.started": "2023-04-29T18:25:26.585028Z"
    },
    "id": "HiYZI7lZSdzF",
    "outputId": "e08a5d15-d652-4423-e5a7-a1a5f820c58f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:01<00:00, 56.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "num_features = resnet50.fc.in_features\n",
    "\n",
    "resnet50.fc = torch.nn.Linear(num_features, 120, bias=True)\n",
    "\n",
    "# check if gpu is available\n",
    "if use_cuda:\n",
    "    resnet50 = resnet50.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:30:48.726258Z",
     "iopub.status.busy": "2023-04-29T18:30:48.725772Z",
     "iopub.status.idle": "2023-04-29T18:30:48.734033Z",
     "shell.execute_reply": "2023-04-29T18:30:48.732674Z",
     "shell.execute_reply.started": "2023-04-29T18:30:48.726209Z"
    },
    "id": "iG-j21pESdzF"
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "grad_weights = filter(lambda w: w.requires_grad, resnet50.parameters())\n",
    "optimizer = torch.optim.Adam(grad_weights, lr=0.01, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:31:00.897500Z",
     "iopub.status.busy": "2023-04-29T18:31:00.897074Z",
     "iopub.status.idle": "2023-04-29T18:31:00.911372Z",
     "shell.execute_reply": "2023-04-29T18:31:00.910196Z",
     "shell.execute_reply.started": "2023-04-29T18:31:00.897462Z"
    },
    "id": "3ZWakSBZSdzF"
   },
   "outputs": [],
   "source": [
    "def train(n_epochs, img_transforms, model, optimizer, criterion, use_cuda):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss_during_train = 0.0\n",
    "        loss_during_validation = 0.0\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for index_batch, (image, label) in enumerate(img_transforms['train']):\n",
    "            if use_cuda:\n",
    "                image, label = image.cuda(), label.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(image)\n",
    "            \n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_during_train = loss_during_train + ((1 / (index_batch + 1)) * (loss.data - loss_during_train))\n",
    "            \n",
    "            if index_batch % 10 == 0:\n",
    "                print(f'Epoch: {epoch} \\tBatch: {index_batch + 1} \\tTraining Loss: {loss_during_train:.2f}')\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in img_transforms['valid']:\n",
    "                if use_cuda:\n",
    "                    images = images.cuda()\n",
    "                    labels = labels.cuda()\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        print(f'Accuracy of the network on the {total} validation images: {100 * correct / total} %') \n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        for index_batch, (image, label) in enumerate(img_transforms['valid']):\n",
    "            if use_cuda:\n",
    "                image, label = image.cuda(), label.cuda()\n",
    "\n",
    "            output = model(image)\n",
    "            \n",
    "            loss = criterion(output, label)\n",
    "            loss_during_validation = loss_during_validation + ((1 / (index_batch + 1)) * (loss.data - loss_during_validation))\n",
    "            \n",
    "        print(f'Epoch: {epoch} \\tTraining Loss: {loss_during_train:.2f} \\tValidation Loss: {loss_during_validation:.2f}')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zMbBPI9iSdzF",
    "outputId": "842a68cc-b539-4081-a50d-45ea18300897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tBatch: 1 \tTraining Loss: 4.83\n",
      "Epoch: 1 \tBatch: 11 \tTraining Loss: 13.02\n",
      "Epoch: 1 \tBatch: 21 \tTraining Loss: 13.17\n",
      "Epoch: 1 \tBatch: 31 \tTraining Loss: 11.89\n",
      "Epoch: 1 \tBatch: 41 \tTraining Loss: 10.41\n",
      "Epoch: 1 \tBatch: 51 \tTraining Loss: 9.16\n",
      "Epoch: 1 \tBatch: 61 \tTraining Loss: 8.18\n",
      "Accuracy of the network on the 1533 validation images: 54.403131115459885 %\n",
      "Epoch: 1 \tTraining Loss: 7.78 \tValidation Loss: 1.81\n",
      "Epoch: 2 \tBatch: 1 \tTraining Loss: 2.46\n",
      "Epoch: 2 \tBatch: 11 \tTraining Loss: 2.79\n",
      "Epoch: 2 \tBatch: 21 \tTraining Loss: 2.79\n",
      "Epoch: 2 \tBatch: 31 \tTraining Loss: 2.80\n",
      "Epoch: 2 \tBatch: 41 \tTraining Loss: 2.73\n",
      "Epoch: 2 \tBatch: 51 \tTraining Loss: 2.65\n",
      "Epoch: 2 \tBatch: 61 \tTraining Loss: 2.60\n",
      "Accuracy of the network on the 1533 validation images: 57.142857142857146 %\n",
      "Epoch: 2 \tTraining Loss: 2.59 \tValidation Loss: 1.68\n",
      "Epoch: 3 \tBatch: 1 \tTraining Loss: 2.80\n",
      "Epoch: 3 \tBatch: 11 \tTraining Loss: 2.85\n",
      "Epoch: 3 \tBatch: 21 \tTraining Loss: 2.84\n",
      "Epoch: 3 \tBatch: 31 \tTraining Loss: 2.72\n",
      "Epoch: 3 \tBatch: 41 \tTraining Loss: 2.65\n",
      "Epoch: 3 \tBatch: 51 \tTraining Loss: 2.61\n",
      "Epoch: 3 \tBatch: 61 \tTraining Loss: 2.62\n",
      "Accuracy of the network on the 1533 validation images: 55.25114155251141 %\n",
      "Epoch: 3 \tTraining Loss: 2.63 \tValidation Loss: 1.77\n",
      "Epoch: 4 \tBatch: 1 \tTraining Loss: 2.83\n",
      "Epoch: 4 \tBatch: 11 \tTraining Loss: 3.16\n",
      "Epoch: 4 \tBatch: 21 \tTraining Loss: 3.15\n",
      "Epoch: 4 \tBatch: 31 \tTraining Loss: 2.97\n",
      "Epoch: 4 \tBatch: 41 \tTraining Loss: 2.88\n",
      "Epoch: 4 \tBatch: 51 \tTraining Loss: 2.84\n",
      "Epoch: 4 \tBatch: 61 \tTraining Loss: 2.80\n",
      "Accuracy of the network on the 1533 validation images: 52.707110241356816 %\n",
      "Epoch: 4 \tTraining Loss: 2.82 \tValidation Loss: 1.88\n",
      "Epoch: 5 \tBatch: 1 \tTraining Loss: 2.82\n",
      "Epoch: 5 \tBatch: 11 \tTraining Loss: 3.16\n",
      "Epoch: 5 \tBatch: 21 \tTraining Loss: 3.03\n",
      "Epoch: 5 \tBatch: 31 \tTraining Loss: 2.89\n",
      "Epoch: 5 \tBatch: 41 \tTraining Loss: 2.80\n",
      "Epoch: 5 \tBatch: 51 \tTraining Loss: 2.80\n",
      "Epoch: 5 \tBatch: 61 \tTraining Loss: 2.77\n",
      "Accuracy of the network on the 1533 validation images: 53.68558382257012 %\n",
      "Epoch: 5 \tTraining Loss: 2.76 \tValidation Loss: 1.91\n",
      "Epoch: 6 \tBatch: 1 \tTraining Loss: 2.63\n",
      "Epoch: 6 \tBatch: 11 \tTraining Loss: 2.92\n",
      "Epoch: 6 \tBatch: 21 \tTraining Loss: 2.97\n",
      "Epoch: 6 \tBatch: 31 \tTraining Loss: 2.95\n",
      "Epoch: 6 \tBatch: 41 \tTraining Loss: 2.88\n",
      "Epoch: 6 \tBatch: 51 \tTraining Loss: 2.84\n",
      "Epoch: 6 \tBatch: 61 \tTraining Loss: 2.78\n",
      "Accuracy of the network on the 1533 validation images: 59.752120026092626 %\n",
      "Epoch: 6 \tTraining Loss: 2.77 \tValidation Loss: 1.49\n",
      "Epoch: 7 \tBatch: 1 \tTraining Loss: 2.36\n",
      "Epoch: 7 \tBatch: 11 \tTraining Loss: 2.85\n",
      "Epoch: 7 \tBatch: 21 \tTraining Loss: 3.09\n",
      "Epoch: 7 \tBatch: 31 \tTraining Loss: 3.21\n",
      "Epoch: 7 \tBatch: 41 \tTraining Loss: 3.14\n",
      "Epoch: 7 \tBatch: 51 \tTraining Loss: 3.09\n",
      "Epoch: 7 \tBatch: 61 \tTraining Loss: 3.04\n",
      "Accuracy of the network on the 1533 validation images: 57.20808871493803 %\n",
      "Epoch: 7 \tTraining Loss: 3.00 \tValidation Loss: 1.89\n",
      "Epoch: 8 \tBatch: 1 \tTraining Loss: 3.35\n",
      "Epoch: 8 \tBatch: 11 \tTraining Loss: 3.13\n",
      "Epoch: 8 \tBatch: 21 \tTraining Loss: 3.11\n",
      "Epoch: 8 \tBatch: 31 \tTraining Loss: 3.02\n",
      "Epoch: 8 \tBatch: 41 \tTraining Loss: 2.99\n",
      "Epoch: 8 \tBatch: 51 \tTraining Loss: 2.93\n",
      "Epoch: 8 \tBatch: 61 \tTraining Loss: 2.90\n",
      "Accuracy of the network on the 1533 validation images: 62.88323548597521 %\n",
      "Epoch: 8 \tTraining Loss: 2.89 \tValidation Loss: 1.66\n",
      "Epoch: 9 \tBatch: 1 \tTraining Loss: 2.09\n",
      "Epoch: 9 \tBatch: 11 \tTraining Loss: 2.84\n",
      "Epoch: 9 \tBatch: 21 \tTraining Loss: 2.92\n",
      "Epoch: 9 \tBatch: 31 \tTraining Loss: 2.79\n",
      "Epoch: 9 \tBatch: 41 \tTraining Loss: 2.82\n",
      "Epoch: 9 \tBatch: 51 \tTraining Loss: 2.81\n",
      "Epoch: 9 \tBatch: 61 \tTraining Loss: 2.78\n",
      "Accuracy of the network on the 1533 validation images: 52.96803652968037 %\n",
      "Epoch: 9 \tTraining Loss: 2.78 \tValidation Loss: 2.03\n",
      "Epoch: 10 \tBatch: 1 \tTraining Loss: 3.21\n",
      "Epoch: 10 \tBatch: 11 \tTraining Loss: 2.99\n",
      "Epoch: 10 \tBatch: 21 \tTraining Loss: 2.89\n",
      "Epoch: 10 \tBatch: 31 \tTraining Loss: 2.79\n",
      "Epoch: 10 \tBatch: 41 \tTraining Loss: 2.74\n",
      "Epoch: 10 \tBatch: 51 \tTraining Loss: 2.76\n",
      "Epoch: 10 \tBatch: 61 \tTraining Loss: 2.75\n",
      "Accuracy of the network on the 1533 validation images: 61.31767775603392 %\n",
      "Epoch: 10 \tTraining Loss: 2.75 \tValidation Loss: 1.58\n",
      "Epoch: 11 \tBatch: 1 \tTraining Loss: 3.07\n",
      "Epoch: 11 \tBatch: 11 \tTraining Loss: 2.99\n",
      "Epoch: 11 \tBatch: 21 \tTraining Loss: 3.08\n",
      "Epoch: 11 \tBatch: 31 \tTraining Loss: 2.98\n",
      "Epoch: 11 \tBatch: 41 \tTraining Loss: 2.94\n",
      "Epoch: 11 \tBatch: 51 \tTraining Loss: 2.92\n",
      "Epoch: 11 \tBatch: 61 \tTraining Loss: 2.90\n",
      "Accuracy of the network on the 1533 validation images: 60.14350945857795 %\n",
      "Epoch: 11 \tTraining Loss: 2.87 \tValidation Loss: 1.65\n",
      "Epoch: 12 \tBatch: 1 \tTraining Loss: 3.03\n",
      "Epoch: 12 \tBatch: 11 \tTraining Loss: 3.09\n",
      "Epoch: 12 \tBatch: 21 \tTraining Loss: 2.93\n",
      "Epoch: 12 \tBatch: 31 \tTraining Loss: 2.91\n",
      "Epoch: 12 \tBatch: 41 \tTraining Loss: 3.01\n",
      "Epoch: 12 \tBatch: 51 \tTraining Loss: 2.97\n",
      "Epoch: 12 \tBatch: 61 \tTraining Loss: 2.92\n",
      "Accuracy of the network on the 1533 validation images: 56.425309849967384 %\n",
      "Epoch: 12 \tTraining Loss: 2.90 \tValidation Loss: 1.83\n",
      "Epoch: 13 \tBatch: 1 \tTraining Loss: 2.78\n",
      "Epoch: 13 \tBatch: 11 \tTraining Loss: 3.02\n",
      "Epoch: 13 \tBatch: 21 \tTraining Loss: 3.02\n",
      "Epoch: 13 \tBatch: 31 \tTraining Loss: 3.04\n",
      "Epoch: 13 \tBatch: 41 \tTraining Loss: 3.03\n",
      "Epoch: 13 \tBatch: 51 \tTraining Loss: 3.00\n",
      "Epoch: 13 \tBatch: 61 \tTraining Loss: 2.98\n",
      "Accuracy of the network on the 1533 validation images: 47.292889758643184 %\n",
      "Epoch: 13 \tTraining Loss: 2.96 \tValidation Loss: 2.29\n",
      "Epoch: 14 \tBatch: 1 \tTraining Loss: 4.23\n",
      "Epoch: 14 \tBatch: 11 \tTraining Loss: 3.52\n",
      "Epoch: 14 \tBatch: 21 \tTraining Loss: 3.51\n",
      "Epoch: 14 \tBatch: 31 \tTraining Loss: 3.36\n",
      "Epoch: 14 \tBatch: 41 \tTraining Loss: 3.24\n",
      "Epoch: 14 \tBatch: 51 \tTraining Loss: 3.15\n",
      "Epoch: 14 \tBatch: 61 \tTraining Loss: 3.08\n",
      "Accuracy of the network on the 1533 validation images: 55.446836268754076 %\n",
      "Epoch: 14 \tTraining Loss: 3.08 \tValidation Loss: 2.00\n",
      "Epoch: 15 \tBatch: 1 \tTraining Loss: 3.05\n",
      "Epoch: 15 \tBatch: 11 \tTraining Loss: 3.27\n",
      "Epoch: 15 \tBatch: 21 \tTraining Loss: 3.12\n",
      "Epoch: 15 \tBatch: 31 \tTraining Loss: 2.94\n",
      "Epoch: 15 \tBatch: 41 \tTraining Loss: 2.88\n",
      "Epoch: 15 \tBatch: 51 \tTraining Loss: 2.82\n",
      "Epoch: 15 \tBatch: 61 \tTraining Loss: 2.79\n",
      "Accuracy of the network on the 1533 validation images: 54.53359425962166 %\n",
      "Epoch: 15 \tTraining Loss: 2.80 \tValidation Loss: 2.00\n",
      "Epoch: 16 \tBatch: 1 \tTraining Loss: 3.21\n",
      "Epoch: 16 \tBatch: 11 \tTraining Loss: 3.28\n",
      "Epoch: 16 \tBatch: 21 \tTraining Loss: 3.10\n",
      "Epoch: 16 \tBatch: 31 \tTraining Loss: 3.07\n",
      "Epoch: 16 \tBatch: 41 \tTraining Loss: 3.06\n",
      "Epoch: 16 \tBatch: 51 \tTraining Loss: 3.03\n",
      "Epoch: 16 \tBatch: 61 \tTraining Loss: 3.05\n",
      "Accuracy of the network on the 1533 validation images: 59.03457273320287 %\n",
      "Epoch: 16 \tTraining Loss: 3.04 \tValidation Loss: 1.85\n",
      "Epoch: 17 \tBatch: 1 \tTraining Loss: 2.52\n",
      "Epoch: 17 \tBatch: 11 \tTraining Loss: 3.00\n",
      "Epoch: 17 \tBatch: 21 \tTraining Loss: 2.85\n",
      "Epoch: 17 \tBatch: 31 \tTraining Loss: 2.83\n",
      "Epoch: 17 \tBatch: 41 \tTraining Loss: 2.77\n",
      "Epoch: 17 \tBatch: 51 \tTraining Loss: 2.73\n",
      "Epoch: 17 \tBatch: 61 \tTraining Loss: 2.71\n",
      "Accuracy of the network on the 1533 validation images: 50.61969993476843 %\n",
      "Epoch: 17 \tTraining Loss: 2.71 \tValidation Loss: 2.17\n",
      "Epoch: 18 \tBatch: 1 \tTraining Loss: 2.72\n",
      "Epoch: 18 \tBatch: 11 \tTraining Loss: 3.35\n",
      "Epoch: 18 \tBatch: 21 \tTraining Loss: 3.44\n",
      "Epoch: 18 \tBatch: 31 \tTraining Loss: 3.32\n",
      "Epoch: 18 \tBatch: 41 \tTraining Loss: 3.32\n",
      "Epoch: 18 \tBatch: 51 \tTraining Loss: 3.30\n",
      "Epoch: 18 \tBatch: 61 \tTraining Loss: 3.26\n",
      "Accuracy of the network on the 1533 validation images: 56.55577299412916 %\n",
      "Epoch: 18 \tTraining Loss: 3.24 \tValidation Loss: 2.08\n",
      "Epoch: 19 \tBatch: 1 \tTraining Loss: 3.00\n",
      "Epoch: 19 \tBatch: 11 \tTraining Loss: 3.34\n",
      "Epoch: 19 \tBatch: 21 \tTraining Loss: 3.24\n",
      "Epoch: 19 \tBatch: 31 \tTraining Loss: 3.09\n",
      "Epoch: 19 \tBatch: 41 \tTraining Loss: 3.03\n",
      "Epoch: 19 \tBatch: 51 \tTraining Loss: 3.01\n",
      "Epoch: 19 \tBatch: 61 \tTraining Loss: 2.97\n",
      "Accuracy of the network on the 1533 validation images: 54.07697325505545 %\n",
      "Epoch: 19 \tTraining Loss: 2.97 \tValidation Loss: 1.97\n",
      "Epoch: 20 \tBatch: 1 \tTraining Loss: 2.86\n",
      "Epoch: 20 \tBatch: 11 \tTraining Loss: 3.08\n",
      "Epoch: 20 \tBatch: 21 \tTraining Loss: 2.97\n",
      "Epoch: 20 \tBatch: 31 \tTraining Loss: 2.81\n",
      "Epoch: 20 \tBatch: 41 \tTraining Loss: 2.75\n",
      "Epoch: 20 \tBatch: 51 \tTraining Loss: 2.75\n",
      "Epoch: 20 \tBatch: 61 \tTraining Loss: 2.77\n",
      "Accuracy of the network on the 1533 validation images: 51.7938682322244 %\n",
      "Epoch: 20 \tTraining Loss: 2.77 \tValidation Loss: 2.03\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "output_model =  train(n_epochs, dataloaders, resnet50, optimizer, loss_function, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8QXGG_lfddN"
   },
   "outputs": [],
   "source": [
    "def redirect_error():\n",
    "    sys.stderr = open('/dev/null', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_bwAzkjVUXa",
    "outputId": "7e2aba71-0c7e-4ab1-f068-e40ce6a84887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2172 testing images:  52.90 %\n"
     ]
    }
   ],
   "source": [
    "redirect_error()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in dataloaders['test']:\n",
    "    if use_cuda:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = resnet50(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} testing images: {100 * correct / total: .2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-FB_kGDh71W"
   },
   "source": [
    "# The accuracy is more that random guess. But let's run more epochs and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTJxfoxgiDEY",
    "outputId": "9ecacfe2-6cf2-4f6c-c439-b9568f7bc6ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tBatch: 1 \tTraining Loss: 3.36\n",
      "Epoch: 1 \tBatch: 11 \tTraining Loss: 3.62\n",
      "Epoch: 1 \tBatch: 21 \tTraining Loss: 3.39\n",
      "Epoch: 1 \tBatch: 31 \tTraining Loss: 3.29\n",
      "Epoch: 1 \tBatch: 41 \tTraining Loss: 3.23\n",
      "Epoch: 1 \tBatch: 51 \tTraining Loss: 3.30\n",
      "Epoch: 1 \tBatch: 61 \tTraining Loss: 3.32\n",
      "Accuracy of the network on the 1533 validation images: 52.707110241356816 %\n",
      "Epoch: 1 \tTraining Loss: 3.31 \tValidation Loss: 2.19\n",
      "Epoch: 2 \tBatch: 1 \tTraining Loss: 3.73\n",
      "Epoch: 2 \tBatch: 11 \tTraining Loss: 3.74\n",
      "Epoch: 2 \tBatch: 21 \tTraining Loss: 3.53\n",
      "Epoch: 2 \tBatch: 31 \tTraining Loss: 3.33\n",
      "Epoch: 2 \tBatch: 41 \tTraining Loss: 3.21\n",
      "Epoch: 2 \tBatch: 51 \tTraining Loss: 3.13\n",
      "Epoch: 2 \tBatch: 61 \tTraining Loss: 3.09\n",
      "Accuracy of the network on the 1533 validation images: 58.96934116112198 %\n",
      "Epoch: 2 \tTraining Loss: 3.07 \tValidation Loss: 1.61\n",
      "Epoch: 3 \tBatch: 1 \tTraining Loss: 2.28\n",
      "Epoch: 3 \tBatch: 11 \tTraining Loss: 3.06\n",
      "Epoch: 3 \tBatch: 21 \tTraining Loss: 2.93\n",
      "Epoch: 3 \tBatch: 31 \tTraining Loss: 2.97\n",
      "Epoch: 3 \tBatch: 41 \tTraining Loss: 2.98\n",
      "Epoch: 3 \tBatch: 51 \tTraining Loss: 3.01\n",
      "Epoch: 3 \tBatch: 61 \tTraining Loss: 3.05\n",
      "Accuracy of the network on the 1533 validation images: 55.64253098499674 %\n",
      "Epoch: 3 \tTraining Loss: 3.04 \tValidation Loss: 1.98\n",
      "Epoch: 4 \tBatch: 1 \tTraining Loss: 2.71\n",
      "Epoch: 4 \tBatch: 11 \tTraining Loss: 3.29\n",
      "Epoch: 4 \tBatch: 21 \tTraining Loss: 3.01\n",
      "Epoch: 4 \tBatch: 31 \tTraining Loss: 2.94\n",
      "Epoch: 4 \tBatch: 41 \tTraining Loss: 2.91\n",
      "Epoch: 4 \tBatch: 51 \tTraining Loss: 2.88\n",
      "Epoch: 4 \tBatch: 61 \tTraining Loss: 2.92\n",
      "Accuracy of the network on the 1533 validation images: 47.61904761904762 %\n",
      "Epoch: 4 \tTraining Loss: 2.93 \tValidation Loss: 2.38\n",
      "Epoch: 5 \tBatch: 1 \tTraining Loss: 3.48\n",
      "Epoch: 5 \tBatch: 11 \tTraining Loss: 3.58\n",
      "Epoch: 5 \tBatch: 21 \tTraining Loss: 3.49\n",
      "Epoch: 5 \tBatch: 31 \tTraining Loss: 3.55\n",
      "Epoch: 5 \tBatch: 41 \tTraining Loss: 3.58\n",
      "Epoch: 5 \tBatch: 51 \tTraining Loss: 3.45\n",
      "Epoch: 5 \tBatch: 61 \tTraining Loss: 3.34\n",
      "Accuracy of the network on the 1533 validation images: 56.490541422048274 %\n",
      "Epoch: 5 \tTraining Loss: 3.32 \tValidation Loss: 2.12\n",
      "Epoch: 6 \tBatch: 1 \tTraining Loss: 2.64\n",
      "Epoch: 6 \tBatch: 11 \tTraining Loss: 3.19\n",
      "Epoch: 6 \tBatch: 21 \tTraining Loss: 3.18\n",
      "Epoch: 6 \tBatch: 31 \tTraining Loss: 3.12\n",
      "Epoch: 6 \tBatch: 41 \tTraining Loss: 3.08\n",
      "Epoch: 6 \tBatch: 51 \tTraining Loss: 3.04\n",
      "Epoch: 6 \tBatch: 61 \tTraining Loss: 3.02\n",
      "Accuracy of the network on the 1533 validation images: 55.64253098499674 %\n",
      "Epoch: 6 \tTraining Loss: 3.03 \tValidation Loss: 1.94\n",
      "Epoch: 7 \tBatch: 1 \tTraining Loss: 3.23\n",
      "Epoch: 7 \tBatch: 11 \tTraining Loss: 3.04\n",
      "Epoch: 7 \tBatch: 21 \tTraining Loss: 2.89\n",
      "Epoch: 7 \tBatch: 31 \tTraining Loss: 2.89\n",
      "Epoch: 7 \tBatch: 41 \tTraining Loss: 2.83\n",
      "Epoch: 7 \tBatch: 51 \tTraining Loss: 2.84\n",
      "Epoch: 7 \tBatch: 61 \tTraining Loss: 2.85\n",
      "Accuracy of the network on the 1533 validation images: 56.68623613829093 %\n",
      "Epoch: 7 \tTraining Loss: 2.87 \tValidation Loss: 1.97\n",
      "Epoch: 8 \tBatch: 1 \tTraining Loss: 3.45\n",
      "Epoch: 8 \tBatch: 11 \tTraining Loss: 3.43\n",
      "Epoch: 8 \tBatch: 21 \tTraining Loss: 3.38\n",
      "Epoch: 8 \tBatch: 31 \tTraining Loss: 3.16\n",
      "Epoch: 8 \tBatch: 41 \tTraining Loss: 3.08\n",
      "Epoch: 8 \tBatch: 51 \tTraining Loss: 2.99\n",
      "Epoch: 8 \tBatch: 61 \tTraining Loss: 2.94\n",
      "Accuracy of the network on the 1533 validation images: 54.66405740378343 %\n",
      "Epoch: 8 \tTraining Loss: 2.91 \tValidation Loss: 1.71\n",
      "Epoch: 9 \tBatch: 1 \tTraining Loss: 2.90\n",
      "Epoch: 9 \tBatch: 11 \tTraining Loss: 3.02\n",
      "Epoch: 9 \tBatch: 21 \tTraining Loss: 3.01\n",
      "Epoch: 9 \tBatch: 31 \tTraining Loss: 2.97\n",
      "Epoch: 9 \tBatch: 41 \tTraining Loss: 2.88\n",
      "Epoch: 9 \tBatch: 51 \tTraining Loss: 2.83\n",
      "Epoch: 9 \tBatch: 61 \tTraining Loss: 2.86\n",
      "Accuracy of the network on the 1533 validation images: 54.99021526418787 %\n",
      "Epoch: 9 \tTraining Loss: 2.86 \tValidation Loss: 2.00\n",
      "Epoch: 10 \tBatch: 1 \tTraining Loss: 3.00\n",
      "Epoch: 10 \tBatch: 11 \tTraining Loss: 3.32\n",
      "Epoch: 10 \tBatch: 21 \tTraining Loss: 3.21\n",
      "Epoch: 10 \tBatch: 31 \tTraining Loss: 3.05\n",
      "Epoch: 10 \tBatch: 41 \tTraining Loss: 2.98\n",
      "Epoch: 10 \tBatch: 51 \tTraining Loss: 2.94\n",
      "Epoch: 10 \tBatch: 61 \tTraining Loss: 2.90\n",
      "Accuracy of the network on the 1533 validation images: 56.81669928245271 %\n",
      "Epoch: 10 \tTraining Loss: 2.88 \tValidation Loss: 1.84\n",
      "Epoch: 11 \tBatch: 1 \tTraining Loss: 3.03\n",
      "Epoch: 11 \tBatch: 11 \tTraining Loss: 3.48\n",
      "Epoch: 11 \tBatch: 21 \tTraining Loss: 3.37\n",
      "Epoch: 11 \tBatch: 31 \tTraining Loss: 3.25\n",
      "Epoch: 11 \tBatch: 41 \tTraining Loss: 3.13\n",
      "Epoch: 11 \tBatch: 51 \tTraining Loss: 3.06\n",
      "Epoch: 11 \tBatch: 61 \tTraining Loss: 3.04\n",
      "Accuracy of the network on the 1533 validation images: 57.40378343118069 %\n",
      "Epoch: 11 \tTraining Loss: 3.03 \tValidation Loss: 1.84\n",
      "Epoch: 12 \tBatch: 1 \tTraining Loss: 2.76\n",
      "Epoch: 12 \tBatch: 11 \tTraining Loss: 3.06\n",
      "Epoch: 12 \tBatch: 21 \tTraining Loss: 2.90\n",
      "Epoch: 12 \tBatch: 31 \tTraining Loss: 2.80\n",
      "Epoch: 12 \tBatch: 41 \tTraining Loss: 2.82\n",
      "Epoch: 12 \tBatch: 51 \tTraining Loss: 2.80\n",
      "Epoch: 12 \tBatch: 61 \tTraining Loss: 2.83\n",
      "Accuracy of the network on the 1533 validation images: 59.29549902152642 %\n",
      "Epoch: 12 \tTraining Loss: 2.82 \tValidation Loss: 2.32\n",
      "Epoch: 13 \tBatch: 1 \tTraining Loss: 3.41\n",
      "Epoch: 13 \tBatch: 11 \tTraining Loss: 3.48\n",
      "Epoch: 13 \tBatch: 21 \tTraining Loss: 3.55\n",
      "Epoch: 13 \tBatch: 31 \tTraining Loss: 3.37\n",
      "Epoch: 13 \tBatch: 41 \tTraining Loss: 3.26\n",
      "Epoch: 13 \tBatch: 51 \tTraining Loss: 3.21\n",
      "Epoch: 13 \tBatch: 61 \tTraining Loss: 3.14\n",
      "Accuracy of the network on the 1533 validation images: 58.77364644487932 %\n",
      "Epoch: 13 \tTraining Loss: 3.15 \tValidation Loss: 1.90\n",
      "Epoch: 14 \tBatch: 1 \tTraining Loss: 3.53\n",
      "Epoch: 14 \tBatch: 11 \tTraining Loss: 3.20\n",
      "Epoch: 14 \tBatch: 21 \tTraining Loss: 3.00\n",
      "Epoch: 14 \tBatch: 31 \tTraining Loss: 2.97\n",
      "Epoch: 14 \tBatch: 41 \tTraining Loss: 2.92\n",
      "Epoch: 14 \tBatch: 51 \tTraining Loss: 2.91\n",
      "Epoch: 14 \tBatch: 61 \tTraining Loss: 2.92\n",
      "Accuracy of the network on the 1533 validation images: 53.881278538812786 %\n",
      "Epoch: 14 \tTraining Loss: 2.94 \tValidation Loss: 2.20\n",
      "Epoch: 15 \tBatch: 1 \tTraining Loss: 2.90\n",
      "Epoch: 15 \tBatch: 11 \tTraining Loss: 3.40\n",
      "Epoch: 15 \tBatch: 21 \tTraining Loss: 3.23\n",
      "Epoch: 15 \tBatch: 31 \tTraining Loss: 3.18\n",
      "Epoch: 15 \tBatch: 41 \tTraining Loss: 3.11\n",
      "Epoch: 15 \tBatch: 51 \tTraining Loss: 3.13\n",
      "Epoch: 15 \tBatch: 61 \tTraining Loss: 3.13\n",
      "Accuracy of the network on the 1533 validation images: 45.00978473581213 %\n",
      "Epoch: 15 \tTraining Loss: 3.14 \tValidation Loss: 2.51\n",
      "Epoch: 16 \tBatch: 1 \tTraining Loss: 3.38\n",
      "Epoch: 16 \tBatch: 11 \tTraining Loss: 4.34\n",
      "Epoch: 16 \tBatch: 21 \tTraining Loss: 3.98\n",
      "Epoch: 16 \tBatch: 31 \tTraining Loss: 3.75\n",
      "Epoch: 16 \tBatch: 41 \tTraining Loss: 3.66\n",
      "Epoch: 16 \tBatch: 51 \tTraining Loss: 3.52\n",
      "Epoch: 16 \tBatch: 61 \tTraining Loss: 3.42\n",
      "Accuracy of the network on the 1533 validation images: 52.054794520547944 %\n",
      "Epoch: 16 \tTraining Loss: 3.38 \tValidation Loss: 2.05\n",
      "Epoch: 17 \tBatch: 1 \tTraining Loss: 3.16\n",
      "Epoch: 17 \tBatch: 11 \tTraining Loss: 3.55\n",
      "Epoch: 17 \tBatch: 21 \tTraining Loss: 3.33\n",
      "Epoch: 17 \tBatch: 31 \tTraining Loss: 3.24\n",
      "Epoch: 17 \tBatch: 41 \tTraining Loss: 3.14\n",
      "Epoch: 17 \tBatch: 51 \tTraining Loss: 3.08\n",
      "Epoch: 17 \tBatch: 61 \tTraining Loss: 3.03\n",
      "Accuracy of the network on the 1533 validation images: 58.44748858447488 %\n",
      "Epoch: 17 \tTraining Loss: 3.04 \tValidation Loss: 1.76\n",
      "Epoch: 18 \tBatch: 1 \tTraining Loss: 2.99\n",
      "Epoch: 18 \tBatch: 11 \tTraining Loss: 3.38\n",
      "Epoch: 18 \tBatch: 21 \tTraining Loss: 3.21\n",
      "Epoch: 18 \tBatch: 31 \tTraining Loss: 3.11\n",
      "Epoch: 18 \tBatch: 41 \tTraining Loss: 3.02\n",
      "Epoch: 18 \tBatch: 51 \tTraining Loss: 2.94\n",
      "Epoch: 18 \tBatch: 61 \tTraining Loss: 2.93\n",
      "Accuracy of the network on the 1533 validation images: 61.12198303979126 %\n",
      "Epoch: 18 \tTraining Loss: 2.94 \tValidation Loss: 1.64\n",
      "Epoch: 19 \tBatch: 1 \tTraining Loss: 3.20\n",
      "Epoch: 19 \tBatch: 11 \tTraining Loss: 3.00\n",
      "Epoch: 19 \tBatch: 21 \tTraining Loss: 2.87\n",
      "Epoch: 19 \tBatch: 31 \tTraining Loss: 2.86\n",
      "Epoch: 19 \tBatch: 41 \tTraining Loss: 2.86\n",
      "Epoch: 19 \tBatch: 51 \tTraining Loss: 2.89\n",
      "Epoch: 19 \tBatch: 61 \tTraining Loss: 2.89\n",
      "Accuracy of the network on the 1533 validation images: 56.29484670580561 %\n",
      "Epoch: 19 \tTraining Loss: 2.89 \tValidation Loss: 1.86\n",
      "Epoch: 20 \tBatch: 1 \tTraining Loss: 2.52\n",
      "Epoch: 20 \tBatch: 11 \tTraining Loss: 2.84\n",
      "Epoch: 20 \tBatch: 21 \tTraining Loss: 2.97\n",
      "Epoch: 20 \tBatch: 31 \tTraining Loss: 3.04\n",
      "Epoch: 20 \tBatch: 41 \tTraining Loss: 3.02\n",
      "Epoch: 20 \tBatch: 51 \tTraining Loss: 2.99\n",
      "Epoch: 20 \tBatch: 61 \tTraining Loss: 2.96\n",
      "Accuracy of the network on the 1533 validation images: 51.663405088062625 %\n",
      "Epoch: 20 \tTraining Loss: 2.94 \tValidation Loss: 1.96\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "output_model =  train(n_epochs, dataloaders, resnet50, optimizer, loss_function, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBK2TZezoH-e"
   },
   "source": [
    "## Lets see the accuracy now. We see little changes in training and validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfXHeFo3oOqS",
    "outputId": "329f4b86-2d80-4b11-9fbd-6d6369e7ada0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2172 testing images:  54.83 %\n"
     ]
    }
   ],
   "source": [
    "redirect_error()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in dataloaders['test']:\n",
    "    if use_cuda:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = resnet50(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} testing images: {100 * correct / total: .2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZSYzCXpoV2Z"
   },
   "source": [
    "# Great! The accuracy improved albeit very small. But, let's run another 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bgQ4oCb1obip",
    "outputId": "726b82d3-12f7-456b-da84-f80553960082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tBatch: 1 \tTraining Loss: 4.16\n",
      "Epoch: 1 \tBatch: 11 \tTraining Loss: 3.39\n",
      "Epoch: 1 \tBatch: 21 \tTraining Loss: 3.33\n",
      "Epoch: 1 \tBatch: 31 \tTraining Loss: 3.29\n",
      "Epoch: 1 \tBatch: 41 \tTraining Loss: 3.23\n",
      "Epoch: 1 \tBatch: 51 \tTraining Loss: 3.10\n",
      "Epoch: 1 \tBatch: 61 \tTraining Loss: 3.06\n",
      "Accuracy of the network on the 1533 validation images: 58.31702544031311 %\n",
      "Epoch: 1 \tTraining Loss: 3.07 \tValidation Loss: 1.72\n",
      "Epoch: 2 \tBatch: 1 \tTraining Loss: 2.78\n",
      "Epoch: 2 \tBatch: 11 \tTraining Loss: 3.03\n",
      "Epoch: 2 \tBatch: 21 \tTraining Loss: 3.02\n",
      "Epoch: 2 \tBatch: 31 \tTraining Loss: 3.00\n",
      "Epoch: 2 \tBatch: 41 \tTraining Loss: 2.91\n",
      "Epoch: 2 \tBatch: 51 \tTraining Loss: 2.91\n",
      "Epoch: 2 \tBatch: 61 \tTraining Loss: 2.89\n",
      "Accuracy of the network on the 1533 validation images: 52.38095238095238 %\n",
      "Epoch: 2 \tTraining Loss: 2.90 \tValidation Loss: 1.98\n",
      "Epoch: 3 \tBatch: 1 \tTraining Loss: 3.64\n",
      "Epoch: 3 \tBatch: 11 \tTraining Loss: 3.72\n",
      "Epoch: 3 \tBatch: 21 \tTraining Loss: 3.75\n",
      "Epoch: 3 \tBatch: 31 \tTraining Loss: 3.55\n",
      "Epoch: 3 \tBatch: 41 \tTraining Loss: 3.46\n",
      "Epoch: 3 \tBatch: 51 \tTraining Loss: 3.38\n",
      "Epoch: 3 \tBatch: 61 \tTraining Loss: 3.29\n",
      "Accuracy of the network on the 1533 validation images: 52.64187866927593 %\n",
      "Epoch: 3 \tTraining Loss: 3.28 \tValidation Loss: 1.99\n",
      "Epoch: 4 \tBatch: 1 \tTraining Loss: 3.53\n",
      "Epoch: 4 \tBatch: 11 \tTraining Loss: 3.41\n",
      "Epoch: 4 \tBatch: 21 \tTraining Loss: 3.62\n",
      "Epoch: 4 \tBatch: 31 \tTraining Loss: 3.52\n",
      "Epoch: 4 \tBatch: 41 \tTraining Loss: 3.44\n",
      "Epoch: 4 \tBatch: 51 \tTraining Loss: 3.33\n",
      "Epoch: 4 \tBatch: 61 \tTraining Loss: 3.26\n",
      "Accuracy of the network on the 1533 validation images: 55.968688845401175 %\n",
      "Epoch: 4 \tTraining Loss: 3.22 \tValidation Loss: 1.79\n",
      "Epoch: 5 \tBatch: 1 \tTraining Loss: 2.34\n",
      "Epoch: 5 \tBatch: 11 \tTraining Loss: 2.87\n",
      "Epoch: 5 \tBatch: 21 \tTraining Loss: 2.71\n",
      "Epoch: 5 \tBatch: 31 \tTraining Loss: 2.65\n",
      "Epoch: 5 \tBatch: 41 \tTraining Loss: 2.66\n",
      "Epoch: 5 \tBatch: 51 \tTraining Loss: 2.70\n",
      "Epoch: 5 \tBatch: 61 \tTraining Loss: 2.68\n",
      "Accuracy of the network on the 1533 validation images: 58.12133072407045 %\n",
      "Epoch: 5 \tTraining Loss: 2.67 \tValidation Loss: 1.61\n",
      "Epoch: 6 \tBatch: 1 \tTraining Loss: 2.53\n",
      "Epoch: 6 \tBatch: 11 \tTraining Loss: 2.99\n",
      "Epoch: 6 \tBatch: 21 \tTraining Loss: 3.07\n",
      "Epoch: 6 \tBatch: 31 \tTraining Loss: 3.07\n",
      "Epoch: 6 \tBatch: 41 \tTraining Loss: 2.97\n",
      "Epoch: 6 \tBatch: 51 \tTraining Loss: 2.95\n",
      "Epoch: 6 \tBatch: 61 \tTraining Loss: 2.92\n",
      "Accuracy of the network on the 1533 validation images: 56.360078277886494 %\n",
      "Epoch: 6 \tTraining Loss: 2.93 \tValidation Loss: 1.77\n",
      "Epoch: 7 \tBatch: 1 \tTraining Loss: 2.88\n",
      "Epoch: 7 \tBatch: 11 \tTraining Loss: 3.30\n",
      "Epoch: 7 \tBatch: 21 \tTraining Loss: 3.18\n",
      "Epoch: 7 \tBatch: 31 \tTraining Loss: 3.03\n",
      "Epoch: 7 \tBatch: 41 \tTraining Loss: 2.93\n",
      "Epoch: 7 \tBatch: 51 \tTraining Loss: 2.90\n",
      "Epoch: 7 \tBatch: 61 \tTraining Loss: 2.92\n",
      "Accuracy of the network on the 1533 validation images: 59.36073059360731 %\n",
      "Epoch: 7 \tTraining Loss: 2.91 \tValidation Loss: 1.65\n",
      "Epoch: 8 \tBatch: 1 \tTraining Loss: 2.65\n",
      "Epoch: 8 \tBatch: 11 \tTraining Loss: 3.26\n",
      "Epoch: 8 \tBatch: 21 \tTraining Loss: 2.96\n",
      "Epoch: 8 \tBatch: 31 \tTraining Loss: 2.93\n",
      "Epoch: 8 \tBatch: 41 \tTraining Loss: 2.95\n",
      "Epoch: 8 \tBatch: 51 \tTraining Loss: 2.97\n",
      "Epoch: 8 \tBatch: 61 \tTraining Loss: 2.93\n",
      "Accuracy of the network on the 1533 validation images: 57.27332028701892 %\n",
      "Epoch: 8 \tTraining Loss: 2.94 \tValidation Loss: 1.75\n",
      "Epoch: 9 \tBatch: 1 \tTraining Loss: 2.94\n",
      "Epoch: 9 \tBatch: 11 \tTraining Loss: 3.10\n",
      "Epoch: 9 \tBatch: 21 \tTraining Loss: 3.05\n",
      "Epoch: 9 \tBatch: 31 \tTraining Loss: 3.03\n",
      "Epoch: 9 \tBatch: 41 \tTraining Loss: 2.96\n",
      "Epoch: 9 \tBatch: 51 \tTraining Loss: 2.97\n",
      "Epoch: 9 \tBatch: 61 \tTraining Loss: 2.97\n",
      "Accuracy of the network on the 1533 validation images: 51.40247879973907 %\n",
      "Epoch: 9 \tTraining Loss: 3.01 \tValidation Loss: 2.27\n",
      "Epoch: 10 \tBatch: 1 \tTraining Loss: 3.12\n",
      "Epoch: 10 \tBatch: 11 \tTraining Loss: 3.51\n",
      "Epoch: 10 \tBatch: 21 \tTraining Loss: 3.43\n",
      "Epoch: 10 \tBatch: 31 \tTraining Loss: 3.36\n",
      "Epoch: 10 \tBatch: 41 \tTraining Loss: 3.26\n",
      "Epoch: 10 \tBatch: 51 \tTraining Loss: 3.18\n",
      "Epoch: 10 \tBatch: 61 \tTraining Loss: 3.14\n",
      "Accuracy of the network on the 1533 validation images: 57.077625570776256 %\n",
      "Epoch: 10 \tTraining Loss: 3.16 \tValidation Loss: 1.84\n",
      "Epoch: 11 \tBatch: 1 \tTraining Loss: 3.50\n",
      "Epoch: 11 \tBatch: 11 \tTraining Loss: 3.66\n",
      "Epoch: 11 \tBatch: 21 \tTraining Loss: 3.51\n",
      "Epoch: 11 \tBatch: 31 \tTraining Loss: 3.37\n",
      "Epoch: 11 \tBatch: 41 \tTraining Loss: 3.35\n",
      "Epoch: 11 \tBatch: 51 \tTraining Loss: 3.27\n",
      "Epoch: 11 \tBatch: 61 \tTraining Loss: 3.20\n",
      "Accuracy of the network on the 1533 validation images: 58.44748858447488 %\n",
      "Epoch: 11 \tTraining Loss: 3.18 \tValidation Loss: 1.90\n",
      "Epoch: 12 \tBatch: 1 \tTraining Loss: 2.98\n",
      "Epoch: 12 \tBatch: 11 \tTraining Loss: 3.83\n",
      "Epoch: 12 \tBatch: 21 \tTraining Loss: 3.49\n",
      "Epoch: 12 \tBatch: 31 \tTraining Loss: 3.26\n",
      "Epoch: 12 \tBatch: 41 \tTraining Loss: 3.13\n",
      "Epoch: 12 \tBatch: 51 \tTraining Loss: 3.05\n",
      "Epoch: 12 \tBatch: 61 \tTraining Loss: 3.04\n",
      "Accuracy of the network on the 1533 validation images: 54.859752120026094 %\n",
      "Epoch: 12 \tTraining Loss: 3.03 \tValidation Loss: 1.78\n",
      "Epoch: 13 \tBatch: 1 \tTraining Loss: 3.15\n",
      "Epoch: 13 \tBatch: 11 \tTraining Loss: 3.50\n",
      "Epoch: 13 \tBatch: 21 \tTraining Loss: 3.40\n",
      "Epoch: 13 \tBatch: 31 \tTraining Loss: 3.35\n",
      "Epoch: 13 \tBatch: 41 \tTraining Loss: 3.32\n",
      "Epoch: 13 \tBatch: 51 \tTraining Loss: 3.26\n",
      "Epoch: 13 \tBatch: 61 \tTraining Loss: 3.24\n",
      "Accuracy of the network on the 1533 validation images: 50.29354207436399 %\n",
      "Epoch: 13 \tTraining Loss: 3.25 \tValidation Loss: 2.23\n",
      "Epoch: 14 \tBatch: 1 \tTraining Loss: 3.93\n",
      "Epoch: 14 \tBatch: 11 \tTraining Loss: 3.79\n",
      "Epoch: 14 \tBatch: 21 \tTraining Loss: 3.46\n",
      "Epoch: 14 \tBatch: 31 \tTraining Loss: 3.30\n",
      "Epoch: 14 \tBatch: 41 \tTraining Loss: 3.14\n",
      "Epoch: 14 \tBatch: 51 \tTraining Loss: 3.07\n",
      "Epoch: 14 \tBatch: 61 \tTraining Loss: 3.04\n",
      "Accuracy of the network on the 1533 validation images: 57.3385518590998 %\n",
      "Epoch: 14 \tTraining Loss: 3.04 \tValidation Loss: 1.93\n",
      "Epoch: 15 \tBatch: 1 \tTraining Loss: 2.58\n",
      "Epoch: 15 \tBatch: 11 \tTraining Loss: 2.87\n",
      "Epoch: 15 \tBatch: 21 \tTraining Loss: 2.88\n",
      "Epoch: 15 \tBatch: 31 \tTraining Loss: 2.82\n",
      "Epoch: 15 \tBatch: 41 \tTraining Loss: 2.84\n",
      "Epoch: 15 \tBatch: 51 \tTraining Loss: 2.85\n",
      "Epoch: 15 \tBatch: 61 \tTraining Loss: 2.87\n",
      "Accuracy of the network on the 1533 validation images: 48.467058056099155 %\n",
      "Epoch: 15 \tTraining Loss: 2.89 \tValidation Loss: 2.31\n",
      "Epoch: 16 \tBatch: 1 \tTraining Loss: 3.12\n",
      "Epoch: 16 \tBatch: 11 \tTraining Loss: 3.53\n",
      "Epoch: 16 \tBatch: 21 \tTraining Loss: 3.47\n",
      "Epoch: 16 \tBatch: 31 \tTraining Loss: 3.24\n",
      "Epoch: 16 \tBatch: 41 \tTraining Loss: 3.15\n",
      "Epoch: 16 \tBatch: 51 \tTraining Loss: 3.09\n",
      "Epoch: 16 \tBatch: 61 \tTraining Loss: 3.03\n",
      "Accuracy of the network on the 1533 validation images: 53.42465753424658 %\n",
      "Epoch: 16 \tTraining Loss: 3.01 \tValidation Loss: 2.10\n",
      "Epoch: 17 \tBatch: 1 \tTraining Loss: 2.71\n",
      "Epoch: 17 \tBatch: 11 \tTraining Loss: 3.10\n",
      "Epoch: 17 \tBatch: 21 \tTraining Loss: 2.98\n",
      "Epoch: 17 \tBatch: 31 \tTraining Loss: 2.88\n",
      "Epoch: 17 \tBatch: 41 \tTraining Loss: 2.87\n",
      "Epoch: 17 \tBatch: 51 \tTraining Loss: 2.82\n",
      "Epoch: 17 \tBatch: 61 \tTraining Loss: 2.81\n",
      "Accuracy of the network on the 1533 validation images: 58.708414872798436 %\n",
      "Epoch: 17 \tTraining Loss: 2.81 \tValidation Loss: 1.64\n",
      "Epoch: 18 \tBatch: 1 \tTraining Loss: 2.99\n",
      "Epoch: 18 \tBatch: 11 \tTraining Loss: 3.16\n",
      "Epoch: 18 \tBatch: 21 \tTraining Loss: 3.15\n",
      "Epoch: 18 \tBatch: 31 \tTraining Loss: 3.10\n",
      "Epoch: 18 \tBatch: 41 \tTraining Loss: 3.04\n",
      "Epoch: 18 \tBatch: 51 \tTraining Loss: 3.05\n",
      "Epoch: 18 \tBatch: 61 \tTraining Loss: 3.07\n",
      "Accuracy of the network on the 1533 validation images: 49.2498369210698 %\n",
      "Epoch: 18 \tTraining Loss: 3.10 \tValidation Loss: 2.26\n",
      "Epoch: 19 \tBatch: 1 \tTraining Loss: 3.84\n",
      "Epoch: 19 \tBatch: 11 \tTraining Loss: 3.93\n",
      "Epoch: 19 \tBatch: 21 \tTraining Loss: 3.94\n",
      "Epoch: 19 \tBatch: 31 \tTraining Loss: 3.61\n",
      "Epoch: 19 \tBatch: 41 \tTraining Loss: 3.40\n",
      "Epoch: 19 \tBatch: 51 \tTraining Loss: 3.22\n",
      "Epoch: 19 \tBatch: 61 \tTraining Loss: 3.14\n",
      "Accuracy of the network on the 1533 validation images: 52.3157208088715 %\n",
      "Epoch: 19 \tTraining Loss: 3.13 \tValidation Loss: 2.00\n",
      "Epoch: 20 \tBatch: 1 \tTraining Loss: 3.03\n",
      "Epoch: 20 \tBatch: 11 \tTraining Loss: 3.54\n",
      "Epoch: 20 \tBatch: 21 \tTraining Loss: 3.38\n",
      "Epoch: 20 \tBatch: 31 \tTraining Loss: 3.28\n",
      "Epoch: 20 \tBatch: 41 \tTraining Loss: 3.27\n",
      "Epoch: 20 \tBatch: 51 \tTraining Loss: 3.21\n",
      "Epoch: 20 \tBatch: 61 \tTraining Loss: 3.15\n",
      "Accuracy of the network on the 1533 validation images: 57.142857142857146 %\n",
      "Epoch: 20 \tTraining Loss: 3.13 \tValidation Loss: 1.78\n"
     ]
    }
   ],
   "source": [
    "output_model =  train(n_epochs, dataloaders, resnet50, optimizer, loss_function, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgzzWp04uT8B"
   },
   "source": [
    "## It seems to oscillating now. So, let's stop here. We can also try a different optimizer and see if we could decrease the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzXkEHUbuqo1"
   },
   "source": [
    "## Final Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMCdfg74uuig",
    "outputId": "f8c50c79-f8aa-43f6-b71c-3f3c5b56198e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2172 testing images:  58.84 %\n"
     ]
    }
   ],
   "source": [
    "redirect_error()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "final_predictions = []\n",
    "final_labels = []\n",
    "\n",
    "f = []\n",
    "for images, labels in dataloaders['test']:\n",
    "    if use_cuda:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = resnet50(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    \n",
    "    final_predictions.extend(predicted.tolist())\n",
    "    final_labels.extend(labels.tolist())\n",
    "    \n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "print(f'Accuracy of the network on the {total} testing images: {100 * correct / total: .2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xmEH_61LvAvP"
   },
   "outputs": [],
   "source": [
    "acc_score = accuracy_score(final_labels, final_predictions)\n",
    "precision = precision_score(final_labels, final_predictions, average='macro')\n",
    "recall = recall_score(final_labels, final_predictions, average='macro')\n",
    "f1 = f1_score(final_labels, final_predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mkccg-7vI9Y",
    "outputId": "44566f2b-cbb2-4f55-e011-34ab0e655e12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0, 24,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0, 20, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 14,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0, 10,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0, 11]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(final_labels, final_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2WAhbB9vK3_",
    "outputId": "298b7d2c-a51f-4c67-d734-f5eb07b440bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('              precision    recall  f1-score   support\\n'\n",
      " '\\n'\n",
      " '           0       1.00      0.92      0.96        12\\n'\n",
      " '           1       0.77      0.96      0.86        25\\n'\n",
      " '           2       1.00      0.91      0.95        22\\n'\n",
      " '           3       0.93      0.78      0.85        18\\n'\n",
      " '           4       0.19      0.95      0.32        20\\n'\n",
      " '           5       0.00      0.00      0.00        15\\n'\n",
      " '           6       1.00      0.48      0.65        23\\n'\n",
      " '           7       1.00      0.59      0.74        17\\n'\n",
      " '           8       1.00      0.37      0.54        19\\n'\n",
      " '           9       0.67      0.62      0.65        16\\n'\n",
      " '          10       1.00      0.65      0.79        17\\n'\n",
      " '          11       0.91      0.72      0.81        29\\n'\n",
      " '          12       0.67      0.67      0.67        15\\n'\n",
      " '          13       1.00      0.09      0.17        22\\n'\n",
      " '          14       0.00      0.00      0.00        12\\n'\n",
      " '          15       1.00      0.62      0.77         8\\n'\n",
      " '          16       0.67      0.12      0.21        16\\n'\n",
      " '          17       0.96      0.93      0.95        28\\n'\n",
      " '          18       0.82      0.86      0.84        21\\n'\n",
      " '          19       0.80      0.70      0.74        23\\n'\n",
      " '          20       0.00      0.00      0.00        18\\n'\n",
      " '          21       0.00      0.00      0.00        20\\n'\n",
      " '          22       1.00      0.89      0.94        18\\n'\n",
      " '          23       0.71      0.85      0.77        20\\n'\n",
      " '          24       1.00      0.37      0.54        19\\n'\n",
      " '          25       0.48      0.86      0.62        14\\n'\n",
      " '          26       0.81      0.78      0.79        32\\n'\n",
      " '          27       0.67      0.22      0.33        18\\n'\n",
      " '          28       1.00      0.14      0.25        21\\n'\n",
      " '          29       0.14      0.88      0.24         8\\n'\n",
      " '          30       1.00      0.55      0.71        11\\n'\n",
      " '          31       1.00      0.38      0.56        13\\n'\n",
      " '          32       0.64      0.94      0.76        17\\n'\n",
      " '          33       0.50      0.10      0.17        20\\n'\n",
      " '          34       1.00      0.43      0.60        14\\n'\n",
      " '          35       0.46      0.89      0.60        18\\n'\n",
      " '          36       0.82      1.00      0.90        18\\n'\n",
      " '          37       1.00      0.37      0.54        19\\n'\n",
      " '          38       1.00      0.33      0.50        15\\n'\n",
      " '          39       0.56      0.67      0.61        15\\n'\n",
      " '          40       0.86      0.86      0.86        14\\n'\n",
      " '          41       1.00      0.50      0.67        14\\n'\n",
      " '          42       0.36      1.00      0.53        27\\n'\n",
      " '          43       0.00      0.00      0.00        13\\n'\n",
      " '          44       0.83      0.42      0.56        12\\n'\n",
      " '          45       0.65      0.76      0.70        17\\n'\n",
      " '          46       0.48      0.87      0.62        15\\n'\n",
      " '          47       0.29      1.00      0.45        12\\n'\n",
      " '          48       0.89      0.57      0.70        14\\n'\n",
      " '          49       1.00      0.44      0.61        16\\n'\n",
      " '          50       0.79      0.88      0.83        17\\n'\n",
      " '          51       1.00      0.15      0.27        13\\n'\n",
      " '          52       0.67      0.89      0.76        27\\n'\n",
      " '          53       1.00      0.05      0.10        19\\n'\n",
      " '          54       1.00      0.29      0.44        14\\n'\n",
      " '          55       1.00      0.75      0.86        16\\n'\n",
      " '          56       0.75      0.95      0.84        19\\n'\n",
      " '          57       1.00      0.53      0.69        17\\n'\n",
      " '          58       0.70      0.95      0.81        22\\n'\n",
      " '          59       0.22      0.95      0.36        20\\n'\n",
      " '          60       1.00      0.22      0.36        18\\n'\n",
      " '          61       0.33      1.00      0.49        17\\n'\n",
      " '          62       0.59      0.94      0.72        18\\n'\n",
      " '          63       1.00      0.05      0.10        20\\n'\n",
      " '          64       0.41      0.94      0.58        18\\n'\n",
      " '          65       1.00      0.50      0.67        14\\n'\n",
      " '          66       0.86      0.38      0.52        16\\n'\n",
      " '          67       0.25      0.87      0.39        15\\n'\n",
      " '          68       1.00      0.33      0.50        18\\n'\n",
      " '          69       0.36      1.00      0.53        21\\n'\n",
      " '          70       0.39      0.76      0.52        17\\n'\n",
      " '          71       0.50      0.05      0.09        20\\n'\n",
      " '          72       1.00      0.47      0.64        17\\n'\n",
      " '          73       0.53      0.93      0.68        27\\n'\n",
      " '          74       1.00      0.94      0.97        17\\n'\n",
      " '          75       0.45      1.00      0.62        23\\n'\n",
      " '          76       0.50      0.12      0.20        16\\n'\n",
      " '          77       0.43      0.89      0.58        18\\n'\n",
      " '          78       0.63      0.71      0.67        17\\n'\n",
      " '          79       1.00      0.18      0.30        17\\n'\n",
      " '          80       0.71      0.94      0.81        18\\n'\n",
      " '          81       0.80      0.71      0.75        17\\n'\n",
      " '          82       1.00      0.67      0.80        18\\n'\n",
      " '          83       1.00      0.38      0.55        21\\n'\n",
      " '          84       1.00      0.16      0.27        19\\n'\n",
      " '          85       1.00      0.22      0.36        23\\n'\n",
      " '          86       0.49      0.95      0.65        21\\n'\n",
      " '          87       0.91      0.88      0.90        34\\n'\n",
      " '          88       0.00      0.00      0.00        18\\n'\n",
      " '          89       0.21      0.92      0.35        13\\n'\n",
      " '          90       0.00      0.00      0.00        18\\n'\n",
      " '          91       0.00      0.00      0.00        20\\n'\n",
      " '          92       0.96      1.00      0.98        22\\n'\n",
      " '          93       1.00      0.76      0.87        17\\n'\n",
      " '          94       0.94      0.75      0.83        20\\n'\n",
      " '          95       0.47      0.95      0.62        21\\n'\n",
      " '          96       1.00      0.59      0.74        17\\n'\n",
      " '          97       0.75      0.10      0.18        29\\n'\n",
      " '          98       1.00      0.57      0.72        23\\n'\n",
      " '          99       0.45      0.88      0.60        16\\n'\n",
      " '         100       0.86      0.24      0.38        25\\n'\n",
      " '         101       0.00      0.00      0.00        19\\n'\n",
      " '         102       0.45      0.78      0.57        18\\n'\n",
      " '         103       0.61      0.73      0.67        15\\n'\n",
      " '         104       1.00      0.14      0.25        14\\n'\n",
      " '         105       0.75      0.50      0.60        18\\n'\n",
      " '         106       0.00      0.00      0.00        18\\n'\n",
      " '         107       1.00      0.63      0.77        19\\n'\n",
      " '         108       1.00      0.11      0.19        19\\n'\n",
      " '         109       0.73      0.96      0.83        23\\n'\n",
      " '         110       0.67      0.14      0.24        14\\n'\n",
      " '         111       1.00      0.71      0.83        14\\n'\n",
      " '         112       1.00      0.15      0.27        13\\n'\n",
      " '         113       0.64      0.41      0.50        17\\n'\n",
      " '         114       1.00      0.48      0.65        21\\n'\n",
      " '         115       0.45      1.00      0.62        14\\n'\n",
      " '         116       0.52      1.00      0.68        15\\n'\n",
      " '         117       0.50      0.93      0.65        15\\n'\n",
      " '         118       0.59      0.71      0.65        14\\n'\n",
      " '         119       0.69      0.79      0.73        14\\n'\n",
      " '\\n'\n",
      " '    accuracy                           0.59      2172\\n'\n",
      " '   macro avg       0.70      0.58      0.55      2172\\n'\n",
      " 'weighted avg       0.71      0.59      0.56      2172\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(classification_report(final_labels, final_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtyEu-xevOyv",
    "outputId": "1dc5e26b-33f5-4de1-d08c-04e9e03aeccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59, Precision: 0.70, Recall: 0.58, F1-Score: 0.55\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {acc_score:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKzdlbTwvThA"
   },
   "outputs": [],
   "source": [
    "torch.save(resnet50.state_dict(), 'resnet50_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_oj3JvavaAf"
   },
   "outputs": [],
   "source": [
    "torch.save(resnet50, 'efficientnet_full_model.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
