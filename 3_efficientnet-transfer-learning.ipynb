{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-29T18:06:20.941718Z",
     "iopub.status.busy": "2023-04-29T18:06:20.940820Z",
     "iopub.status.idle": "2023-04-29T18:06:31.160665Z",
     "shell.execute_reply": "2023-04-29T18:06:31.159271Z",
     "shell.execute_reply.started": "2023-04-29T18:06:20.941679Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tq\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "from PIL import ImageFile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score, classification_report, precision_recall_fscore_support, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import sys\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "import pprint\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:06:31.163542Z",
     "iopub.status.busy": "2023-04-29T18:06:31.162860Z",
     "iopub.status.idle": "2023-04-29T18:06:31.170681Z",
     "shell.execute_reply": "2023-04-29T18:06:31.169315Z",
     "shell.execute_reply.started": "2023-04-29T18:06:31.163502Z"
    }
   },
   "outputs": [],
   "source": [
    "def path_given_id(id, test=False):\n",
    "    \"\"\"\n",
    "    Returns the full path to the image given the id of the image.\n",
    "    Parameters:\n",
    "        - id: The id of the image.\n",
    "        - test: If True returns the relative path from the test folder. Otherwise, returns the relative path to the image from the training folder.\n",
    "    Returns:\n",
    "        - The full relative path to the image with the give in id.\n",
    "    \"\"\"\n",
    "    return IMAGES_PATH + ('train/' if not test else 'test/') + str(id) + '.jpg'\n",
    "\n",
    "def get_img_array(id, test=False):\n",
    "    \"\"\"\n",
    "    Loads the image from the given id, convert the image to a numpy array and return the numpy array.\n",
    "    Parameters:\n",
    "        - id: The id of the image.\n",
    "        - test: If True, loads the image from the test folder. If False,loads the image from the train folder.\n",
    "    Returns:\n",
    "        - The image with the give id as a numpy array.\n",
    "    \"\"\"\n",
    "    img = load_img(path_given_id(id, test), target_size=(224, 224))\n",
    "    return img_to_array(img)\n",
    "\n",
    "# preprocess_input(np.expand_dims(get_image_array(id, test), axis=0)) will convert the image into 1,224,224,3 to give to predict.\n",
    "def process_image(id, test=False):\n",
    "    return preprocess_input(np.expand_dims(get_img_array(id, test), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:06:31.173075Z",
     "iopub.status.busy": "2023-04-29T18:06:31.172342Z",
     "iopub.status.idle": "2023-04-29T18:06:31.846319Z",
     "shell.execute_reply": "2023-04-29T18:06:31.845272Z",
     "shell.execute_reply.started": "2023-04-29T18:06:31.173033Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGES_PATH = '/kaggle/input/dog-breed-identification/'\n",
    "\n",
    "labels = pd.read_csv(IMAGES_PATH +'labels.csv')\n",
    "labelnames = pd.read_csv(IMAGES_PATH  + 'sample_submission.csv').keys()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:06:31.849471Z",
     "iopub.status.busy": "2023-04-29T18:06:31.849062Z",
     "iopub.status.idle": "2023-04-29T18:06:31.935970Z",
     "shell.execute_reply": "2023-04-29T18:06:31.934917Z",
     "shell.execute_reply.started": "2023-04-29T18:06:31.849428Z"
    }
   },
   "outputs": [],
   "source": [
    "codes = range(len(labelnames))\n",
    "breed_to_code = dict(zip(labelnames, codes))\n",
    "code_to_breed = dict(zip(codes, labelnames))\n",
    "\n",
    "labels['target'] =  [breed_to_code[x] for x in labels.breed]\n",
    "labels['rank'] = labels.groupby('breed').rank()['id']\n",
    "labels_pivot = labels.pivot('id', 'breed', 'target').reset_index().fillna(0)\n",
    "\n",
    "training_data = labels_pivot.sample(frac=0.85)\n",
    "validation_data = labels_pivot[~labels_pivot['id'].isin(training_data['id'])]\n",
    "testing_data = training_data.sample(frac=0.25)\n",
    "training_data = training_data[~training_data['id'].isin(testing_data['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:06:31.938258Z",
     "iopub.status.busy": "2023-04-29T18:06:31.937358Z",
     "iopub.status.idle": "2023-04-29T18:06:31.948824Z",
     "shell.execute_reply": "2023-04-29T18:06:31.947117Z",
     "shell.execute_reply.started": "2023-04-29T18:06:31.938213Z"
    }
   },
   "outputs": [],
   "source": [
    "img_transform = {\n",
    "    'valid':transforms.Compose([\n",
    "        transforms.Resize(size = 224, interpolation=InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(size = 224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'train':transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size = 224),\n",
    "        transforms.RandomRotation(degrees = 30),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),  \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  \n",
    "    ]),\n",
    "    'test':transforms.Compose([\n",
    "        transforms.Resize(size = 224, interpolation=InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(size = 224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:06:31.952090Z",
     "iopub.status.busy": "2023-04-29T18:06:31.950889Z",
     "iopub.status.idle": "2023-04-29T18:06:31.962586Z",
     "shell.execute_reply": "2023-04-29T18:06:31.961725Z",
     "shell.execute_reply.started": "2023-04-29T18:06:31.952053Z"
    }
   },
   "outputs": [],
   "source": [
    "class DogDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Create a dataset for pytorch batch loading. This is to load few images into memory at a time instead of all the images at once.\n",
    "    Extends from torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, images_directory, labels, transform):\n",
    "        \"\"\"\n",
    "        Constructor initialization.\n",
    "        Params:\n",
    "            - images_directory: The directory where the images are stored.\n",
    "            - labels: The image labels\n",
    "            - transform: The transformations to perform on the data.\n",
    "        \"\"\"\n",
    "        self.images_directory = images_directory\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.labels is not None:\n",
    "            image_name = f'{self.labels[\"id\"].iloc[index]}.jpg'\n",
    "            full_image_name = self.images_directory + image_name\n",
    "            \n",
    "            final_image = Image.open(full_image_name)\n",
    "            label = self.labels.iloc[index, 1:].astype('float').to_numpy()\n",
    "            label = np.argmax(label)\n",
    "            \n",
    "            if self.transform:\n",
    "                final_image = self.transform(final_image)\n",
    "            \n",
    "            return [final_image, label]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:06:31.966416Z",
     "iopub.status.busy": "2023-04-29T18:06:31.966094Z",
     "iopub.status.idle": "2023-04-29T18:06:31.976621Z",
     "shell.execute_reply": "2023-04-29T18:06:31.975520Z",
     "shell.execute_reply.started": "2023-04-29T18:06:31.966387Z"
    }
   },
   "outputs": [],
   "source": [
    "num_workers = 4\n",
    "batch_size = 100\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "train_img = DogDataset(IMAGES_PATH + 'train/', training_data, transform = img_transform['train'])\n",
    "valid_img = DogDataset(IMAGES_PATH + 'train/', validation_data, transform = img_transform['valid'])\n",
    "test_img = DogDataset(IMAGES_PATH + 'train/', testing_data, transform = img_transform['test'])\n",
    "\n",
    "\n",
    "dataloaders={\n",
    "    'train':torch.utils.data.DataLoader(train_img, batch_size, num_workers = num_workers, shuffle=True),\n",
    "    'valid':torch.utils.data.DataLoader(valid_img, batch_size, num_workers = num_workers, shuffle=False),\n",
    "    'test':torch.utils.data.DataLoader(test_img, batch_size, num_workers = num_workers, shuffle=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Define a baseline model and your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:06:31.979649Z",
     "iopub.status.busy": "2023-04-29T18:06:31.979304Z",
     "iopub.status.idle": "2023-04-29T18:06:47.640817Z",
     "shell.execute_reply": "2023-04-29T18:06:47.639727Z",
     "shell.execute_reply.started": "2023-04-29T18:06:31.979622Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/NVIDIA/DeepLearningExamples/zipball/torchhub\" to /root/.cache/torch/hub/torchhub.zip\n",
      "Downloading: \"https://api.ngc.nvidia.com/v2/models/nvidia/efficientnet_b0_pyt_amp/versions/20.12.0/files/nvidia_efficientnet-b0_210412.pth\" to /root/.cache/torch/hub/checkpoints/nvidia_efficientnet-b0_210412.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b071fe6df3f74906b4de1ca64ca69716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n",
    "\n",
    "# donot calcualte any of te weights. Use pretrained weights.\n",
    "for param in efficientnet.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# replace the last fully connected layer for to suit for our dog breed identification.\n",
    "# Here we have a linear model with 2048 in_features and 120(Our dog breed # of classes) out_features.\n",
    "num_features = efficientnet.classifier.fc.in_features\n",
    "efficientnet.classifier.fc = torch.nn.Linear(num_features, 120, bias=True)\n",
    "\n",
    "# check if gpu is available\n",
    "if use_cuda:\n",
    "    efficientnet = efficientnet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:06:47.642802Z",
     "iopub.status.busy": "2023-04-29T18:06:47.642407Z",
     "iopub.status.idle": "2023-04-29T18:06:47.653639Z",
     "shell.execute_reply": "2023-04-29T18:06:47.652543Z",
     "shell.execute_reply.started": "2023-04-29T18:06:47.642763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1280, out_features=120, bias=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet.classifier.fc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:06:47.660274Z",
     "iopub.status.busy": "2023-04-29T18:06:47.659169Z",
     "iopub.status.idle": "2023-04-29T18:06:47.708354Z",
     "shell.execute_reply": "2023-04-29T18:06:47.707269Z",
     "shell.execute_reply.started": "2023-04-29T18:06:47.660233Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# filter for weights that need to be computed.\n",
    "# We don't compute already computed weights because we don't have the neccessary computational power.\n",
    "# If we have computational power then we will build the model from the architecture, randomly initialize the weights and train our model.\n",
    "grad_weights = filter(lambda w: w.requires_grad, efficientnet.parameters())\n",
    "\n",
    "# use Stochastic Gradient Descent to minimize the loss.\n",
    "optimizer = torch.optim.SGD(grad_weights, lr=0.01, momentum=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:06:47.710433Z",
     "iopub.status.busy": "2023-04-29T18:06:47.710053Z",
     "iopub.status.idle": "2023-04-29T18:06:47.724958Z",
     "shell.execute_reply": "2023-04-29T18:06:47.723525Z",
     "shell.execute_reply.started": "2023-04-29T18:06:47.710392Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(n_epochs, img_transforms, model, optimizer, criterion, use_cuda):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss_during_train = 0.0\n",
    "        loss_during_validation = 0.0\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for index_batch, (image, label) in enumerate(img_transforms['train']):\n",
    "            if use_cuda:\n",
    "                image, label = image.cuda(), label.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(image)\n",
    "            \n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_during_train = loss_during_train + ((1 / (index_batch + 1)) * (loss.data - loss_during_train))\n",
    "            \n",
    "            if index_batch % 10 == 0:\n",
    "                print(f'Epoch: {epoch} \\tBatch: {index_batch + 1} \\tTraining Loss: {loss_during_train:.2f}')\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in img_transforms['valid']:\n",
    "                if use_cuda:\n",
    "                    images = images.cuda()\n",
    "                    labels = labels.cuda()\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        print(f'Accuracy of the network on the {total} validation images: {100 * correct / total} %') \n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        for index_batch, (image, label) in enumerate(img_transforms['valid']):\n",
    "            if use_cuda:\n",
    "                image, label = image.cuda(), label.cuda()\n",
    "\n",
    "            output = model(image)\n",
    "            \n",
    "            loss = criterion(output, label)\n",
    "            loss_during_validation = loss_during_validation + ((1 / (index_batch + 1)) * (loss.data - loss_during_validation))\n",
    "            \n",
    "        print(f'Epoch: {epoch} \\tTraining Loss: {loss_during_train:.2f} \\tValidation Loss: {loss_during_validation:.2f}')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Run a training loop on a training set with both models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:06:47.726651Z",
     "iopub.status.busy": "2023-04-29T18:06:47.726283Z",
     "iopub.status.idle": "2023-04-29T18:26:16.579187Z",
     "shell.execute_reply": "2023-04-29T18:26:16.576876Z",
     "shell.execute_reply.started": "2023-04-29T18:06:47.726595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tBatch: 1 \tTraining Loss: 4.82\n",
      "Epoch: 1 \tBatch: 11 \tTraining Loss: 4.79\n",
      "Epoch: 1 \tBatch: 21 \tTraining Loss: 4.78\n",
      "Epoch: 1 \tBatch: 31 \tTraining Loss: 4.76\n",
      "Epoch: 1 \tBatch: 41 \tTraining Loss: 4.74\n",
      "Epoch: 1 \tBatch: 51 \tTraining Loss: 4.72\n",
      "Epoch: 1 \tBatch: 61 \tTraining Loss: 4.71\n",
      "Accuracy of the network on the 1533 validation images: 12.785388127853881 %\n",
      "Epoch: 1 \tTraining Loss: 4.70 \tValidation Loss: 4.54\n",
      "Epoch: 2 \tBatch: 1 \tTraining Loss: 4.57\n",
      "Epoch: 2 \tBatch: 11 \tTraining Loss: 4.54\n",
      "Epoch: 2 \tBatch: 21 \tTraining Loss: 4.53\n",
      "Epoch: 2 \tBatch: 31 \tTraining Loss: 4.51\n",
      "Epoch: 2 \tBatch: 41 \tTraining Loss: 4.50\n",
      "Epoch: 2 \tBatch: 51 \tTraining Loss: 4.48\n",
      "Epoch: 2 \tBatch: 61 \tTraining Loss: 4.47\n",
      "Accuracy of the network on the 1533 validation images: 25.244618395303327 %\n",
      "Epoch: 2 \tTraining Loss: 4.46 \tValidation Loss: 4.27\n",
      "Epoch: 3 \tBatch: 1 \tTraining Loss: 4.30\n",
      "Epoch: 3 \tBatch: 11 \tTraining Loss: 4.32\n",
      "Epoch: 3 \tBatch: 21 \tTraining Loss: 4.30\n",
      "Epoch: 3 \tBatch: 31 \tTraining Loss: 4.29\n",
      "Epoch: 3 \tBatch: 41 \tTraining Loss: 4.27\n",
      "Epoch: 3 \tBatch: 51 \tTraining Loss: 4.25\n",
      "Epoch: 3 \tBatch: 61 \tTraining Loss: 4.24\n",
      "Accuracy of the network on the 1533 validation images: 30.789302022178735 %\n",
      "Epoch: 3 \tTraining Loss: 4.23 \tValidation Loss: 4.01\n",
      "Epoch: 4 \tBatch: 1 \tTraining Loss: 4.11\n",
      "Epoch: 4 \tBatch: 11 \tTraining Loss: 4.11\n",
      "Epoch: 4 \tBatch: 21 \tTraining Loss: 4.08\n",
      "Epoch: 4 \tBatch: 31 \tTraining Loss: 4.07\n",
      "Epoch: 4 \tBatch: 41 \tTraining Loss: 4.06\n",
      "Epoch: 4 \tBatch: 51 \tTraining Loss: 4.05\n",
      "Epoch: 4 \tBatch: 61 \tTraining Loss: 4.03\n",
      "Accuracy of the network on the 1533 validation images: 35.355512067840834 %\n",
      "Epoch: 4 \tTraining Loss: 4.03 \tValidation Loss: 3.77\n",
      "Epoch: 5 \tBatch: 1 \tTraining Loss: 3.88\n",
      "Epoch: 5 \tBatch: 11 \tTraining Loss: 3.88\n",
      "Epoch: 5 \tBatch: 21 \tTraining Loss: 3.89\n",
      "Epoch: 5 \tBatch: 31 \tTraining Loss: 3.88\n",
      "Epoch: 5 \tBatch: 41 \tTraining Loss: 3.87\n",
      "Epoch: 5 \tBatch: 51 \tTraining Loss: 3.86\n",
      "Epoch: 5 \tBatch: 61 \tTraining Loss: 3.84\n",
      "Accuracy of the network on the 1533 validation images: 39.13894324853229 %\n",
      "Epoch: 5 \tTraining Loss: 3.84 \tValidation Loss: 3.55\n",
      "Epoch: 6 \tBatch: 1 \tTraining Loss: 3.70\n",
      "Epoch: 6 \tBatch: 11 \tTraining Loss: 3.71\n",
      "Epoch: 6 \tBatch: 21 \tTraining Loss: 3.71\n",
      "Epoch: 6 \tBatch: 31 \tTraining Loss: 3.69\n",
      "Epoch: 6 \tBatch: 41 \tTraining Loss: 3.68\n",
      "Epoch: 6 \tBatch: 51 \tTraining Loss: 3.68\n",
      "Epoch: 6 \tBatch: 61 \tTraining Loss: 3.67\n",
      "Accuracy of the network on the 1533 validation images: 41.55251141552512 %\n",
      "Epoch: 6 \tTraining Loss: 3.67 \tValidation Loss: 3.35\n",
      "Epoch: 7 \tBatch: 1 \tTraining Loss: 3.65\n",
      "Epoch: 7 \tBatch: 11 \tTraining Loss: 3.55\n",
      "Epoch: 7 \tBatch: 21 \tTraining Loss: 3.53\n",
      "Epoch: 7 \tBatch: 31 \tTraining Loss: 3.52\n",
      "Epoch: 7 \tBatch: 41 \tTraining Loss: 3.51\n",
      "Epoch: 7 \tBatch: 51 \tTraining Loss: 3.50\n",
      "Epoch: 7 \tBatch: 61 \tTraining Loss: 3.50\n",
      "Accuracy of the network on the 1533 validation images: 44.1617742987606 %\n",
      "Epoch: 7 \tTraining Loss: 3.50 \tValidation Loss: 3.17\n",
      "Epoch: 8 \tBatch: 1 \tTraining Loss: 3.35\n",
      "Epoch: 8 \tBatch: 11 \tTraining Loss: 3.44\n",
      "Epoch: 8 \tBatch: 21 \tTraining Loss: 3.40\n",
      "Epoch: 8 \tBatch: 31 \tTraining Loss: 3.38\n",
      "Epoch: 8 \tBatch: 41 \tTraining Loss: 3.37\n",
      "Epoch: 8 \tBatch: 51 \tTraining Loss: 3.36\n",
      "Epoch: 8 \tBatch: 61 \tTraining Loss: 3.36\n",
      "Accuracy of the network on the 1533 validation images: 45.33594259621657 %\n",
      "Epoch: 8 \tTraining Loss: 3.36 \tValidation Loss: 3.00\n",
      "Epoch: 9 \tBatch: 1 \tTraining Loss: 3.25\n",
      "Epoch: 9 \tBatch: 11 \tTraining Loss: 3.30\n",
      "Epoch: 9 \tBatch: 21 \tTraining Loss: 3.29\n",
      "Epoch: 9 \tBatch: 31 \tTraining Loss: 3.28\n",
      "Epoch: 9 \tBatch: 41 \tTraining Loss: 3.26\n",
      "Epoch: 9 \tBatch: 51 \tTraining Loss: 3.25\n",
      "Epoch: 9 \tBatch: 61 \tTraining Loss: 3.24\n",
      "Accuracy of the network on the 1533 validation images: 48.66275277234181 %\n",
      "Epoch: 9 \tTraining Loss: 3.24 \tValidation Loss: 2.85\n",
      "Epoch: 10 \tBatch: 1 \tTraining Loss: 3.20\n",
      "Epoch: 10 \tBatch: 11 \tTraining Loss: 3.18\n",
      "Epoch: 10 \tBatch: 21 \tTraining Loss: 3.14\n",
      "Epoch: 10 \tBatch: 31 \tTraining Loss: 3.14\n",
      "Epoch: 10 \tBatch: 41 \tTraining Loss: 3.13\n",
      "Epoch: 10 \tBatch: 51 \tTraining Loss: 3.12\n",
      "Epoch: 10 \tBatch: 61 \tTraining Loss: 3.11\n",
      "Accuracy of the network on the 1533 validation images: 49.575994781474236 %\n",
      "Epoch: 10 \tTraining Loss: 3.11 \tValidation Loss: 2.71\n",
      "Epoch: 11 \tBatch: 1 \tTraining Loss: 3.00\n",
      "Epoch: 11 \tBatch: 11 \tTraining Loss: 3.03\n",
      "Epoch: 11 \tBatch: 21 \tTraining Loss: 3.04\n",
      "Epoch: 11 \tBatch: 31 \tTraining Loss: 3.03\n",
      "Epoch: 11 \tBatch: 41 \tTraining Loss: 3.02\n",
      "Epoch: 11 \tBatch: 51 \tTraining Loss: 3.01\n",
      "Epoch: 11 \tBatch: 61 \tTraining Loss: 3.00\n",
      "Accuracy of the network on the 1533 validation images: 51.01108936725375 %\n",
      "Epoch: 11 \tTraining Loss: 3.00 \tValidation Loss: 2.59\n",
      "Epoch: 12 \tBatch: 1 \tTraining Loss: 3.00\n",
      "Epoch: 12 \tBatch: 11 \tTraining Loss: 2.97\n",
      "Epoch: 12 \tBatch: 21 \tTraining Loss: 2.95\n",
      "Epoch: 12 \tBatch: 31 \tTraining Loss: 2.93\n",
      "Epoch: 12 \tBatch: 41 \tTraining Loss: 2.92\n",
      "Epoch: 12 \tBatch: 51 \tTraining Loss: 2.91\n",
      "Epoch: 12 \tBatch: 61 \tTraining Loss: 2.91\n",
      "Accuracy of the network on the 1533 validation images: 52.57664709719504 %\n",
      "Epoch: 12 \tTraining Loss: 2.90 \tValidation Loss: 2.47\n",
      "Epoch: 13 \tBatch: 1 \tTraining Loss: 2.87\n",
      "Epoch: 13 \tBatch: 11 \tTraining Loss: 2.82\n",
      "Epoch: 13 \tBatch: 21 \tTraining Loss: 2.84\n",
      "Epoch: 13 \tBatch: 31 \tTraining Loss: 2.85\n",
      "Epoch: 13 \tBatch: 41 \tTraining Loss: 2.85\n",
      "Epoch: 13 \tBatch: 51 \tTraining Loss: 2.83\n",
      "Epoch: 13 \tBatch: 61 \tTraining Loss: 2.83\n",
      "Accuracy of the network on the 1533 validation images: 52.51141552511415 %\n",
      "Epoch: 13 \tTraining Loss: 2.83 \tValidation Loss: 2.37\n",
      "Epoch: 14 \tBatch: 1 \tTraining Loss: 2.58\n",
      "Epoch: 14 \tBatch: 11 \tTraining Loss: 2.77\n",
      "Epoch: 14 \tBatch: 21 \tTraining Loss: 2.75\n",
      "Epoch: 14 \tBatch: 31 \tTraining Loss: 2.75\n",
      "Epoch: 14 \tBatch: 41 \tTraining Loss: 2.74\n",
      "Epoch: 14 \tBatch: 51 \tTraining Loss: 2.74\n",
      "Epoch: 14 \tBatch: 61 \tTraining Loss: 2.73\n",
      "Accuracy of the network on the 1533 validation images: 55.25114155251141 %\n",
      "Epoch: 14 \tTraining Loss: 2.74 \tValidation Loss: 2.27\n",
      "Epoch: 15 \tBatch: 1 \tTraining Loss: 2.52\n",
      "Epoch: 15 \tBatch: 11 \tTraining Loss: 2.73\n",
      "Epoch: 15 \tBatch: 21 \tTraining Loss: 2.70\n",
      "Epoch: 15 \tBatch: 31 \tTraining Loss: 2.70\n",
      "Epoch: 15 \tBatch: 41 \tTraining Loss: 2.69\n",
      "Epoch: 15 \tBatch: 51 \tTraining Loss: 2.68\n",
      "Epoch: 15 \tBatch: 61 \tTraining Loss: 2.67\n",
      "Accuracy of the network on the 1533 validation images: 55.3163731245923 %\n",
      "Epoch: 15 \tTraining Loss: 2.68 \tValidation Loss: 2.19\n",
      "Epoch: 16 \tBatch: 1 \tTraining Loss: 2.49\n",
      "Epoch: 16 \tBatch: 11 \tTraining Loss: 2.57\n",
      "Epoch: 16 \tBatch: 21 \tTraining Loss: 2.60\n",
      "Epoch: 16 \tBatch: 31 \tTraining Loss: 2.61\n",
      "Epoch: 16 \tBatch: 41 \tTraining Loss: 2.60\n",
      "Epoch: 16 \tBatch: 51 \tTraining Loss: 2.59\n",
      "Epoch: 16 \tBatch: 61 \tTraining Loss: 2.59\n",
      "Accuracy of the network on the 1533 validation images: 55.3163731245923 %\n",
      "Epoch: 16 \tTraining Loss: 2.59 \tValidation Loss: 2.10\n",
      "Epoch: 17 \tBatch: 1 \tTraining Loss: 2.62\n",
      "Epoch: 17 \tBatch: 11 \tTraining Loss: 2.61\n",
      "Epoch: 17 \tBatch: 21 \tTraining Loss: 2.57\n",
      "Epoch: 17 \tBatch: 31 \tTraining Loss: 2.55\n",
      "Epoch: 17 \tBatch: 41 \tTraining Loss: 2.54\n",
      "Epoch: 17 \tBatch: 51 \tTraining Loss: 2.54\n",
      "Epoch: 17 \tBatch: 61 \tTraining Loss: 2.54\n",
      "Accuracy of the network on the 1533 validation images: 56.62100456621005 %\n",
      "Epoch: 17 \tTraining Loss: 2.54 \tValidation Loss: 2.03\n",
      "Epoch: 18 \tBatch: 1 \tTraining Loss: 2.40\n",
      "Epoch: 18 \tBatch: 11 \tTraining Loss: 2.51\n",
      "Epoch: 18 \tBatch: 21 \tTraining Loss: 2.52\n",
      "Epoch: 18 \tBatch: 31 \tTraining Loss: 2.51\n",
      "Epoch: 18 \tBatch: 41 \tTraining Loss: 2.50\n",
      "Epoch: 18 \tBatch: 51 \tTraining Loss: 2.50\n",
      "Epoch: 18 \tBatch: 61 \tTraining Loss: 2.50\n",
      "Accuracy of the network on the 1533 validation images: 58.18656229615134 %\n",
      "Epoch: 18 \tTraining Loss: 2.50 \tValidation Loss: 1.97\n",
      "Epoch: 19 \tBatch: 1 \tTraining Loss: 2.50\n",
      "Epoch: 19 \tBatch: 11 \tTraining Loss: 2.48\n",
      "Epoch: 19 \tBatch: 21 \tTraining Loss: 2.48\n",
      "Epoch: 19 \tBatch: 31 \tTraining Loss: 2.45\n",
      "Epoch: 19 \tBatch: 41 \tTraining Loss: 2.45\n",
      "Epoch: 19 \tBatch: 51 \tTraining Loss: 2.44\n",
      "Epoch: 19 \tBatch: 61 \tTraining Loss: 2.43\n",
      "Accuracy of the network on the 1533 validation images: 58.382257012394 %\n",
      "Epoch: 19 \tTraining Loss: 2.42 \tValidation Loss: 1.91\n",
      "Epoch: 20 \tBatch: 1 \tTraining Loss: 2.64\n",
      "Epoch: 20 \tBatch: 11 \tTraining Loss: 2.47\n",
      "Epoch: 20 \tBatch: 21 \tTraining Loss: 2.44\n",
      "Epoch: 20 \tBatch: 31 \tTraining Loss: 2.41\n",
      "Epoch: 20 \tBatch: 41 \tTraining Loss: 2.42\n",
      "Epoch: 20 \tBatch: 51 \tTraining Loss: 2.41\n",
      "Epoch: 20 \tBatch: 61 \tTraining Loss: 2.40\n",
      "Accuracy of the network on the 1533 validation images: 58.382257012394 %\n",
      "Epoch: 20 \tTraining Loss: 2.40 \tValidation Loss: 1.85\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "output_model =  train(n_epochs, dataloaders, efficientnet, optimizer, loss_function, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-29T05:56:31.010636Z",
     "iopub.status.idle": "2023-04-29T05:56:31.011689Z",
     "shell.execute_reply": "2023-04-29T05:56:31.011434Z",
     "shell.execute_reply.started": "2023-04-29T05:56:31.011405Z"
    }
   },
   "source": [
    "# Lets do 20 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:26:16.582004Z",
     "iopub.status.busy": "2023-04-29T18:26:16.581137Z",
     "iopub.status.idle": "2023-04-29T18:44:50.563539Z",
     "shell.execute_reply": "2023-04-29T18:44:50.561414Z",
     "shell.execute_reply.started": "2023-04-29T18:26:16.581954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tBatch: 1 \tTraining Loss: 2.36\n",
      "Epoch: 1 \tBatch: 11 \tTraining Loss: 2.39\n",
      "Epoch: 1 \tBatch: 21 \tTraining Loss: 2.37\n",
      "Epoch: 1 \tBatch: 31 \tTraining Loss: 2.37\n",
      "Epoch: 1 \tBatch: 41 \tTraining Loss: 2.35\n",
      "Epoch: 1 \tBatch: 51 \tTraining Loss: 2.34\n",
      "Epoch: 1 \tBatch: 61 \tTraining Loss: 2.34\n",
      "Accuracy of the network on the 1533 validation images: 59.42596216568819 %\n",
      "Epoch: 1 \tTraining Loss: 2.34 \tValidation Loss: 1.80\n",
      "Epoch: 2 \tBatch: 1 \tTraining Loss: 2.29\n",
      "Epoch: 2 \tBatch: 11 \tTraining Loss: 2.30\n",
      "Epoch: 2 \tBatch: 21 \tTraining Loss: 2.29\n",
      "Epoch: 2 \tBatch: 31 \tTraining Loss: 2.31\n",
      "Epoch: 2 \tBatch: 41 \tTraining Loss: 2.31\n",
      "Epoch: 2 \tBatch: 51 \tTraining Loss: 2.31\n",
      "Epoch: 2 \tBatch: 61 \tTraining Loss: 2.31\n",
      "Accuracy of the network on the 1533 validation images: 59.68688845401174 %\n",
      "Epoch: 2 \tTraining Loss: 2.31 \tValidation Loss: 1.75\n",
      "Epoch: 3 \tBatch: 1 \tTraining Loss: 2.24\n",
      "Epoch: 3 \tBatch: 11 \tTraining Loss: 2.32\n",
      "Epoch: 3 \tBatch: 21 \tTraining Loss: 2.31\n",
      "Epoch: 3 \tBatch: 31 \tTraining Loss: 2.29\n",
      "Epoch: 3 \tBatch: 41 \tTraining Loss: 2.28\n",
      "Epoch: 3 \tBatch: 51 \tTraining Loss: 2.28\n",
      "Epoch: 3 \tBatch: 61 \tTraining Loss: 2.28\n",
      "Accuracy of the network on the 1533 validation images: 59.55642530984997 %\n",
      "Epoch: 3 \tTraining Loss: 2.28 \tValidation Loss: 1.71\n",
      "Epoch: 4 \tBatch: 1 \tTraining Loss: 2.23\n",
      "Epoch: 4 \tBatch: 11 \tTraining Loss: 2.28\n",
      "Epoch: 4 \tBatch: 21 \tTraining Loss: 2.26\n",
      "Epoch: 4 \tBatch: 31 \tTraining Loss: 2.26\n",
      "Epoch: 4 \tBatch: 41 \tTraining Loss: 2.25\n",
      "Epoch: 4 \tBatch: 51 \tTraining Loss: 2.25\n",
      "Epoch: 4 \tBatch: 61 \tTraining Loss: 2.25\n",
      "Accuracy of the network on the 1533 validation images: 60.66536203522505 %\n",
      "Epoch: 4 \tTraining Loss: 2.24 \tValidation Loss: 1.67\n",
      "Epoch: 5 \tBatch: 1 \tTraining Loss: 2.32\n",
      "Epoch: 5 \tBatch: 11 \tTraining Loss: 2.20\n",
      "Epoch: 5 \tBatch: 21 \tTraining Loss: 2.18\n",
      "Epoch: 5 \tBatch: 31 \tTraining Loss: 2.20\n",
      "Epoch: 5 \tBatch: 41 \tTraining Loss: 2.20\n",
      "Epoch: 5 \tBatch: 51 \tTraining Loss: 2.20\n",
      "Epoch: 5 \tBatch: 61 \tTraining Loss: 2.20\n",
      "Accuracy of the network on the 1533 validation images: 60.795825179386824 %\n",
      "Epoch: 5 \tTraining Loss: 2.19 \tValidation Loss: 1.64\n",
      "Epoch: 6 \tBatch: 1 \tTraining Loss: 2.12\n",
      "Epoch: 6 \tBatch: 11 \tTraining Loss: 2.17\n",
      "Epoch: 6 \tBatch: 21 \tTraining Loss: 2.17\n",
      "Epoch: 6 \tBatch: 31 \tTraining Loss: 2.16\n",
      "Epoch: 6 \tBatch: 41 \tTraining Loss: 2.17\n",
      "Epoch: 6 \tBatch: 51 \tTraining Loss: 2.17\n",
      "Epoch: 6 \tBatch: 61 \tTraining Loss: 2.17\n",
      "Accuracy of the network on the 1533 validation images: 61.448140900195696 %\n",
      "Epoch: 6 \tTraining Loss: 2.16 \tValidation Loss: 1.60\n",
      "Epoch: 7 \tBatch: 1 \tTraining Loss: 2.20\n",
      "Epoch: 7 \tBatch: 11 \tTraining Loss: 2.19\n",
      "Epoch: 7 \tBatch: 21 \tTraining Loss: 2.15\n",
      "Epoch: 7 \tBatch: 31 \tTraining Loss: 2.16\n",
      "Epoch: 7 \tBatch: 41 \tTraining Loss: 2.16\n",
      "Epoch: 7 \tBatch: 51 \tTraining Loss: 2.17\n",
      "Epoch: 7 \tBatch: 61 \tTraining Loss: 2.16\n",
      "Accuracy of the network on the 1533 validation images: 60.339204174820615 %\n",
      "Epoch: 7 \tTraining Loss: 2.17 \tValidation Loss: 1.57\n",
      "Epoch: 8 \tBatch: 1 \tTraining Loss: 2.08\n",
      "Epoch: 8 \tBatch: 11 \tTraining Loss: 2.10\n",
      "Epoch: 8 \tBatch: 21 \tTraining Loss: 2.12\n",
      "Epoch: 8 \tBatch: 31 \tTraining Loss: 2.11\n",
      "Epoch: 8 \tBatch: 41 \tTraining Loss: 2.10\n",
      "Epoch: 8 \tBatch: 51 \tTraining Loss: 2.10\n",
      "Epoch: 8 \tBatch: 61 \tTraining Loss: 2.11\n",
      "Accuracy of the network on the 1533 validation images: 61.18721461187214 %\n",
      "Epoch: 8 \tTraining Loss: 2.11 \tValidation Loss: 1.54\n",
      "Epoch: 9 \tBatch: 1 \tTraining Loss: 2.09\n",
      "Epoch: 9 \tBatch: 11 \tTraining Loss: 2.13\n",
      "Epoch: 9 \tBatch: 21 \tTraining Loss: 2.09\n",
      "Epoch: 9 \tBatch: 31 \tTraining Loss: 2.09\n",
      "Epoch: 9 \tBatch: 41 \tTraining Loss: 2.09\n",
      "Epoch: 9 \tBatch: 51 \tTraining Loss: 2.08\n",
      "Epoch: 9 \tBatch: 61 \tTraining Loss: 2.08\n",
      "Accuracy of the network on the 1533 validation images: 62.23091976516634 %\n",
      "Epoch: 9 \tTraining Loss: 2.08 \tValidation Loss: 1.51\n",
      "Epoch: 10 \tBatch: 1 \tTraining Loss: 2.01\n",
      "Epoch: 10 \tBatch: 11 \tTraining Loss: 2.03\n",
      "Epoch: 10 \tBatch: 21 \tTraining Loss: 2.05\n",
      "Epoch: 10 \tBatch: 31 \tTraining Loss: 2.03\n",
      "Epoch: 10 \tBatch: 41 \tTraining Loss: 2.03\n",
      "Epoch: 10 \tBatch: 51 \tTraining Loss: 2.04\n",
      "Epoch: 10 \tBatch: 61 \tTraining Loss: 2.05\n",
      "Accuracy of the network on the 1533 validation images: 61.31767775603392 %\n",
      "Epoch: 10 \tTraining Loss: 2.05 \tValidation Loss: 1.49\n",
      "Epoch: 11 \tBatch: 1 \tTraining Loss: 1.96\n",
      "Epoch: 11 \tBatch: 11 \tTraining Loss: 2.00\n",
      "Epoch: 11 \tBatch: 21 \tTraining Loss: 2.01\n",
      "Epoch: 11 \tBatch: 31 \tTraining Loss: 2.03\n",
      "Epoch: 11 \tBatch: 41 \tTraining Loss: 2.03\n",
      "Epoch: 11 \tBatch: 51 \tTraining Loss: 2.03\n",
      "Epoch: 11 \tBatch: 61 \tTraining Loss: 2.04\n",
      "Accuracy of the network on the 1533 validation images: 62.62230919765166 %\n",
      "Epoch: 11 \tTraining Loss: 2.04 \tValidation Loss: 1.47\n",
      "Epoch: 12 \tBatch: 1 \tTraining Loss: 1.91\n",
      "Epoch: 12 \tBatch: 11 \tTraining Loss: 2.08\n",
      "Epoch: 12 \tBatch: 21 \tTraining Loss: 2.05\n",
      "Epoch: 12 \tBatch: 31 \tTraining Loss: 2.05\n",
      "Epoch: 12 \tBatch: 41 \tTraining Loss: 2.06\n",
      "Epoch: 12 \tBatch: 51 \tTraining Loss: 2.04\n",
      "Epoch: 12 \tBatch: 61 \tTraining Loss: 2.03\n",
      "Accuracy of the network on the 1533 validation images: 62.49184605348989 %\n",
      "Epoch: 12 \tTraining Loss: 2.03 \tValidation Loss: 1.45\n",
      "Epoch: 13 \tBatch: 1 \tTraining Loss: 1.89\n",
      "Epoch: 13 \tBatch: 11 \tTraining Loss: 2.02\n",
      "Epoch: 13 \tBatch: 21 \tTraining Loss: 1.99\n",
      "Epoch: 13 \tBatch: 31 \tTraining Loss: 1.98\n",
      "Epoch: 13 \tBatch: 41 \tTraining Loss: 2.00\n",
      "Epoch: 13 \tBatch: 51 \tTraining Loss: 1.99\n",
      "Epoch: 13 \tBatch: 61 \tTraining Loss: 2.00\n",
      "Accuracy of the network on the 1533 validation images: 61.57860404435747 %\n",
      "Epoch: 13 \tTraining Loss: 2.00 \tValidation Loss: 1.42\n",
      "Epoch: 14 \tBatch: 1 \tTraining Loss: 1.92\n",
      "Epoch: 14 \tBatch: 11 \tTraining Loss: 2.01\n",
      "Epoch: 14 \tBatch: 21 \tTraining Loss: 2.01\n",
      "Epoch: 14 \tBatch: 31 \tTraining Loss: 2.01\n",
      "Epoch: 14 \tBatch: 41 \tTraining Loss: 2.00\n",
      "Epoch: 14 \tBatch: 51 \tTraining Loss: 2.00\n",
      "Epoch: 14 \tBatch: 61 \tTraining Loss: 1.99\n",
      "Accuracy of the network on the 1533 validation images: 61.904761904761905 %\n",
      "Epoch: 14 \tTraining Loss: 1.99 \tValidation Loss: 1.41\n",
      "Epoch: 15 \tBatch: 1 \tTraining Loss: 2.14\n",
      "Epoch: 15 \tBatch: 11 \tTraining Loss: 2.00\n",
      "Epoch: 15 \tBatch: 21 \tTraining Loss: 1.98\n",
      "Epoch: 15 \tBatch: 31 \tTraining Loss: 1.96\n",
      "Epoch: 15 \tBatch: 41 \tTraining Loss: 1.97\n",
      "Epoch: 15 \tBatch: 51 \tTraining Loss: 1.97\n",
      "Epoch: 15 \tBatch: 61 \tTraining Loss: 1.96\n",
      "Accuracy of the network on the 1533 validation images: 62.68754076973255 %\n",
      "Epoch: 15 \tTraining Loss: 1.96 \tValidation Loss: 1.39\n",
      "Epoch: 16 \tBatch: 1 \tTraining Loss: 1.89\n",
      "Epoch: 16 \tBatch: 11 \tTraining Loss: 1.91\n",
      "Epoch: 16 \tBatch: 21 \tTraining Loss: 1.94\n",
      "Epoch: 16 \tBatch: 31 \tTraining Loss: 1.94\n",
      "Epoch: 16 \tBatch: 41 \tTraining Loss: 1.93\n",
      "Epoch: 16 \tBatch: 51 \tTraining Loss: 1.93\n",
      "Epoch: 16 \tBatch: 61 \tTraining Loss: 1.93\n",
      "Accuracy of the network on the 1533 validation images: 62.948467058056096 %\n",
      "Epoch: 16 \tTraining Loss: 1.94 \tValidation Loss: 1.37\n",
      "Epoch: 17 \tBatch: 1 \tTraining Loss: 2.30\n",
      "Epoch: 17 \tBatch: 11 \tTraining Loss: 1.94\n",
      "Epoch: 17 \tBatch: 21 \tTraining Loss: 1.96\n",
      "Epoch: 17 \tBatch: 31 \tTraining Loss: 1.95\n",
      "Epoch: 17 \tBatch: 41 \tTraining Loss: 1.95\n",
      "Epoch: 17 \tBatch: 51 \tTraining Loss: 1.94\n",
      "Epoch: 17 \tBatch: 61 \tTraining Loss: 1.94\n",
      "Accuracy of the network on the 1533 validation images: 62.81800391389432 %\n",
      "Epoch: 17 \tTraining Loss: 1.93 \tValidation Loss: 1.35\n",
      "Epoch: 18 \tBatch: 1 \tTraining Loss: 2.03\n",
      "Epoch: 18 \tBatch: 11 \tTraining Loss: 1.96\n",
      "Epoch: 18 \tBatch: 21 \tTraining Loss: 1.97\n",
      "Epoch: 18 \tBatch: 31 \tTraining Loss: 1.95\n",
      "Epoch: 18 \tBatch: 41 \tTraining Loss: 1.93\n",
      "Epoch: 18 \tBatch: 51 \tTraining Loss: 1.93\n",
      "Epoch: 18 \tBatch: 61 \tTraining Loss: 1.93\n",
      "Accuracy of the network on the 1533 validation images: 62.88323548597521 %\n",
      "Epoch: 18 \tTraining Loss: 1.94 \tValidation Loss: 1.34\n",
      "Epoch: 19 \tBatch: 1 \tTraining Loss: 1.90\n",
      "Epoch: 19 \tBatch: 11 \tTraining Loss: 1.90\n",
      "Epoch: 19 \tBatch: 21 \tTraining Loss: 1.90\n",
      "Epoch: 19 \tBatch: 31 \tTraining Loss: 1.92\n",
      "Epoch: 19 \tBatch: 41 \tTraining Loss: 1.93\n",
      "Epoch: 19 \tBatch: 51 \tTraining Loss: 1.93\n",
      "Epoch: 19 \tBatch: 61 \tTraining Loss: 1.91\n",
      "Accuracy of the network on the 1533 validation images: 62.948467058056096 %\n",
      "Epoch: 19 \tTraining Loss: 1.91 \tValidation Loss: 1.32\n",
      "Epoch: 20 \tBatch: 1 \tTraining Loss: 2.17\n",
      "Epoch: 20 \tBatch: 11 \tTraining Loss: 1.89\n",
      "Epoch: 20 \tBatch: 21 \tTraining Loss: 1.91\n",
      "Epoch: 20 \tBatch: 31 \tTraining Loss: 1.90\n",
      "Epoch: 20 \tBatch: 41 \tTraining Loss: 1.89\n",
      "Epoch: 20 \tBatch: 51 \tTraining Loss: 1.89\n",
      "Epoch: 20 \tBatch: 61 \tTraining Loss: 1.89\n",
      "Accuracy of the network on the 1533 validation images: 64.05740378343118 %\n",
      "Epoch: 20 \tTraining Loss: 1.89 \tValidation Loss: 1.31\n"
     ]
    }
   ],
   "source": [
    "output_model =  train(n_epochs, dataloaders, efficientnet, optimizer, loss_function, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:44:50.565815Z",
     "iopub.status.busy": "2023-04-29T18:44:50.565492Z",
     "iopub.status.idle": "2023-04-29T18:44:50.572750Z",
     "shell.execute_reply": "2023-04-29T18:44:50.571514Z",
     "shell.execute_reply.started": "2023-04-29T18:44:50.565784Z"
    }
   },
   "outputs": [],
   "source": [
    "def redirect_error():\n",
    "    sys.stderr = open('/dev/null', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:44:50.575569Z",
     "iopub.status.busy": "2023-04-29T18:44:50.574732Z",
     "iopub.status.idle": "2023-04-29T18:45:05.578333Z",
     "shell.execute_reply": "2023-04-29T18:45:05.577353Z",
     "shell.execute_reply.started": "2023-04-29T18:44:50.575528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2172 testing images:  72.88 %\n"
     ]
    }
   ],
   "source": [
    "redirect_error()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in dataloaders['test']:\n",
    "    if use_cuda:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = efficientnet(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} testing images: {100 * correct / total: .2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We are getting pretty good accuracy with this model. Let's try 10 more epochs now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:45:05.581251Z",
     "iopub.status.busy": "2023-04-29T18:45:05.580491Z",
     "iopub.status.idle": "2023-04-29T18:54:17.029234Z",
     "shell.execute_reply": "2023-04-29T18:54:17.028121Z",
     "shell.execute_reply.started": "2023-04-29T18:45:05.581193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tBatch: 1 \tTraining Loss: 1.81\n",
      "Epoch: 1 \tBatch: 11 \tTraining Loss: 1.85\n",
      "Epoch: 1 \tBatch: 21 \tTraining Loss: 1.84\n",
      "Epoch: 1 \tBatch: 31 \tTraining Loss: 1.85\n",
      "Epoch: 1 \tBatch: 41 \tTraining Loss: 1.86\n",
      "Epoch: 1 \tBatch: 51 \tTraining Loss: 1.87\n",
      "Epoch: 1 \tBatch: 61 \tTraining Loss: 1.87\n",
      "Accuracy of the network on the 1533 validation images: 63.27462491846053 %\n",
      "Epoch: 1 \tTraining Loss: 1.86 \tValidation Loss: 1.30\n",
      "Epoch: 2 \tBatch: 1 \tTraining Loss: 1.79\n",
      "Epoch: 2 \tBatch: 11 \tTraining Loss: 1.86\n",
      "Epoch: 2 \tBatch: 21 \tTraining Loss: 1.85\n",
      "Epoch: 2 \tBatch: 31 \tTraining Loss: 1.84\n",
      "Epoch: 2 \tBatch: 41 \tTraining Loss: 1.86\n",
      "Epoch: 2 \tBatch: 51 \tTraining Loss: 1.84\n",
      "Epoch: 2 \tBatch: 61 \tTraining Loss: 1.83\n",
      "Accuracy of the network on the 1533 validation images: 63.926940639269404 %\n",
      "Epoch: 2 \tTraining Loss: 1.84 \tValidation Loss: 1.28\n",
      "Epoch: 3 \tBatch: 1 \tTraining Loss: 1.44\n",
      "Epoch: 3 \tBatch: 11 \tTraining Loss: 1.88\n",
      "Epoch: 3 \tBatch: 21 \tTraining Loss: 1.86\n",
      "Epoch: 3 \tBatch: 31 \tTraining Loss: 1.85\n",
      "Epoch: 3 \tBatch: 41 \tTraining Loss: 1.84\n",
      "Epoch: 3 \tBatch: 51 \tTraining Loss: 1.85\n",
      "Epoch: 3 \tBatch: 61 \tTraining Loss: 1.85\n",
      "Accuracy of the network on the 1533 validation images: 63.078930202217876 %\n",
      "Epoch: 3 \tTraining Loss: 1.85 \tValidation Loss: 1.27\n",
      "Epoch: 4 \tBatch: 1 \tTraining Loss: 1.94\n",
      "Epoch: 4 \tBatch: 11 \tTraining Loss: 1.84\n",
      "Epoch: 4 \tBatch: 21 \tTraining Loss: 1.81\n",
      "Epoch: 4 \tBatch: 31 \tTraining Loss: 1.84\n",
      "Epoch: 4 \tBatch: 41 \tTraining Loss: 1.84\n",
      "Epoch: 4 \tBatch: 51 \tTraining Loss: 1.85\n",
      "Epoch: 4 \tBatch: 61 \tTraining Loss: 1.85\n",
      "Accuracy of the network on the 1533 validation images: 62.81800391389432 %\n",
      "Epoch: 4 \tTraining Loss: 1.86 \tValidation Loss: 1.26\n",
      "Epoch: 5 \tBatch: 1 \tTraining Loss: 1.88\n",
      "Epoch: 5 \tBatch: 11 \tTraining Loss: 1.86\n",
      "Epoch: 5 \tBatch: 21 \tTraining Loss: 1.83\n",
      "Epoch: 5 \tBatch: 31 \tTraining Loss: 1.81\n",
      "Epoch: 5 \tBatch: 41 \tTraining Loss: 1.81\n",
      "Epoch: 5 \tBatch: 51 \tTraining Loss: 1.80\n",
      "Epoch: 5 \tBatch: 61 \tTraining Loss: 1.81\n",
      "Accuracy of the network on the 1533 validation images: 64.12263535551207 %\n",
      "Epoch: 5 \tTraining Loss: 1.81 \tValidation Loss: 1.25\n",
      "Epoch: 6 \tBatch: 1 \tTraining Loss: 2.02\n",
      "Epoch: 6 \tBatch: 11 \tTraining Loss: 1.83\n",
      "Epoch: 6 \tBatch: 21 \tTraining Loss: 1.82\n",
      "Epoch: 6 \tBatch: 31 \tTraining Loss: 1.82\n",
      "Epoch: 6 \tBatch: 41 \tTraining Loss: 1.82\n",
      "Epoch: 6 \tBatch: 51 \tTraining Loss: 1.82\n",
      "Epoch: 6 \tBatch: 61 \tTraining Loss: 1.82\n",
      "Accuracy of the network on the 1533 validation images: 62.81800391389432 %\n",
      "Epoch: 6 \tTraining Loss: 1.81 \tValidation Loss: 1.23\n",
      "Epoch: 7 \tBatch: 1 \tTraining Loss: 1.89\n",
      "Epoch: 7 \tBatch: 11 \tTraining Loss: 1.83\n",
      "Epoch: 7 \tBatch: 21 \tTraining Loss: 1.80\n",
      "Epoch: 7 \tBatch: 31 \tTraining Loss: 1.82\n",
      "Epoch: 7 \tBatch: 41 \tTraining Loss: 1.81\n",
      "Epoch: 7 \tBatch: 51 \tTraining Loss: 1.81\n",
      "Epoch: 7 \tBatch: 61 \tTraining Loss: 1.82\n",
      "Accuracy of the network on the 1533 validation images: 63.992172211350294 %\n",
      "Epoch: 7 \tTraining Loss: 1.82 \tValidation Loss: 1.22\n",
      "Epoch: 8 \tBatch: 1 \tTraining Loss: 1.94\n",
      "Epoch: 8 \tBatch: 11 \tTraining Loss: 1.87\n",
      "Epoch: 8 \tBatch: 21 \tTraining Loss: 1.83\n",
      "Epoch: 8 \tBatch: 31 \tTraining Loss: 1.81\n",
      "Epoch: 8 \tBatch: 41 \tTraining Loss: 1.79\n",
      "Epoch: 8 \tBatch: 51 \tTraining Loss: 1.79\n",
      "Epoch: 8 \tBatch: 61 \tTraining Loss: 1.78\n",
      "Accuracy of the network on the 1533 validation images: 64.44879321591651 %\n",
      "Epoch: 8 \tTraining Loss: 1.80 \tValidation Loss: 1.21\n",
      "Epoch: 9 \tBatch: 1 \tTraining Loss: 1.69\n",
      "Epoch: 9 \tBatch: 11 \tTraining Loss: 1.81\n",
      "Epoch: 9 \tBatch: 21 \tTraining Loss: 1.80\n",
      "Epoch: 9 \tBatch: 31 \tTraining Loss: 1.78\n",
      "Epoch: 9 \tBatch: 41 \tTraining Loss: 1.77\n",
      "Epoch: 9 \tBatch: 51 \tTraining Loss: 1.77\n",
      "Epoch: 9 \tBatch: 61 \tTraining Loss: 1.79\n",
      "Accuracy of the network on the 1533 validation images: 64.05740378343118 %\n",
      "Epoch: 9 \tTraining Loss: 1.79 \tValidation Loss: 1.21\n",
      "Epoch: 10 \tBatch: 1 \tTraining Loss: 1.63\n",
      "Epoch: 10 \tBatch: 11 \tTraining Loss: 1.74\n",
      "Epoch: 10 \tBatch: 21 \tTraining Loss: 1.75\n",
      "Epoch: 10 \tBatch: 31 \tTraining Loss: 1.77\n",
      "Epoch: 10 \tBatch: 41 \tTraining Loss: 1.76\n",
      "Epoch: 10 \tBatch: 51 \tTraining Loss: 1.76\n",
      "Epoch: 10 \tBatch: 61 \tTraining Loss: 1.77\n",
      "Accuracy of the network on the 1533 validation images: 64.70971950424006 %\n",
      "Epoch: 10 \tTraining Loss: 1.78 \tValidation Loss: 1.20\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "output_model =  train(n_epochs, dataloaders, efficientnet, optimizer, loss_function, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's again see what's the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:54:17.032161Z",
     "iopub.status.busy": "2023-04-29T18:54:17.031168Z",
     "iopub.status.idle": "2023-04-29T18:54:29.655271Z",
     "shell.execute_reply": "2023-04-29T18:54:29.654295Z",
     "shell.execute_reply.started": "2023-04-29T18:54:17.032111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2172 testing images:  73.90 %\n"
     ]
    }
   ],
   "source": [
    "redirect_error()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in dataloaders['test']:\n",
    "    if use_cuda:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = efficientnet(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {total} testing images: {100 * correct / total: .2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ok! Let's try 20 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:54:29.660174Z",
     "iopub.status.busy": "2023-04-29T18:54:29.659316Z",
     "iopub.status.idle": "2023-04-29T19:12:56.237372Z",
     "shell.execute_reply": "2023-04-29T19:12:56.236448Z",
     "shell.execute_reply.started": "2023-04-29T18:54:29.660122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tBatch: 1 \tTraining Loss: 1.74\n",
      "Epoch: 1 \tBatch: 11 \tTraining Loss: 1.77\n",
      "Epoch: 1 \tBatch: 21 \tTraining Loss: 1.78\n",
      "Epoch: 1 \tBatch: 31 \tTraining Loss: 1.78\n",
      "Epoch: 1 \tBatch: 41 \tTraining Loss: 1.78\n",
      "Epoch: 1 \tBatch: 51 \tTraining Loss: 1.77\n",
      "Epoch: 1 \tBatch: 61 \tTraining Loss: 1.77\n",
      "Accuracy of the network on the 1533 validation images: 64.18786692759295 %\n",
      "Epoch: 1 \tTraining Loss: 1.78 \tValidation Loss: 1.19\n",
      "Epoch: 2 \tBatch: 1 \tTraining Loss: 1.64\n",
      "Epoch: 2 \tBatch: 11 \tTraining Loss: 1.76\n",
      "Epoch: 2 \tBatch: 21 \tTraining Loss: 1.78\n",
      "Epoch: 2 \tBatch: 31 \tTraining Loss: 1.78\n",
      "Epoch: 2 \tBatch: 41 \tTraining Loss: 1.78\n",
      "Epoch: 2 \tBatch: 51 \tTraining Loss: 1.77\n",
      "Epoch: 2 \tBatch: 61 \tTraining Loss: 1.77\n",
      "Accuracy of the network on the 1533 validation images: 64.44879321591651 %\n",
      "Epoch: 2 \tTraining Loss: 1.77 \tValidation Loss: 1.18\n",
      "Epoch: 3 \tBatch: 1 \tTraining Loss: 1.80\n",
      "Epoch: 3 \tBatch: 11 \tTraining Loss: 1.74\n",
      "Epoch: 3 \tBatch: 21 \tTraining Loss: 1.74\n",
      "Epoch: 3 \tBatch: 31 \tTraining Loss: 1.74\n",
      "Epoch: 3 \tBatch: 41 \tTraining Loss: 1.75\n",
      "Epoch: 3 \tBatch: 51 \tTraining Loss: 1.75\n",
      "Epoch: 3 \tBatch: 61 \tTraining Loss: 1.76\n",
      "Accuracy of the network on the 1533 validation images: 64.90541422048271 %\n",
      "Epoch: 3 \tTraining Loss: 1.75 \tValidation Loss: 1.17\n",
      "Epoch: 4 \tBatch: 1 \tTraining Loss: 1.78\n",
      "Epoch: 4 \tBatch: 11 \tTraining Loss: 1.74\n",
      "Epoch: 4 \tBatch: 21 \tTraining Loss: 1.72\n",
      "Epoch: 4 \tBatch: 31 \tTraining Loss: 1.72\n",
      "Epoch: 4 \tBatch: 41 \tTraining Loss: 1.73\n",
      "Epoch: 4 \tBatch: 51 \tTraining Loss: 1.73\n",
      "Epoch: 4 \tBatch: 61 \tTraining Loss: 1.72\n",
      "Accuracy of the network on the 1533 validation images: 64.44879321591651 %\n",
      "Epoch: 4 \tTraining Loss: 1.73 \tValidation Loss: 1.17\n",
      "Epoch: 5 \tBatch: 1 \tTraining Loss: 1.73\n",
      "Epoch: 5 \tBatch: 11 \tTraining Loss: 1.73\n",
      "Epoch: 5 \tBatch: 21 \tTraining Loss: 1.71\n",
      "Epoch: 5 \tBatch: 31 \tTraining Loss: 1.70\n",
      "Epoch: 5 \tBatch: 41 \tTraining Loss: 1.72\n",
      "Epoch: 5 \tBatch: 51 \tTraining Loss: 1.72\n",
      "Epoch: 5 \tBatch: 61 \tTraining Loss: 1.72\n",
      "Accuracy of the network on the 1533 validation images: 64.25309849967384 %\n",
      "Epoch: 5 \tTraining Loss: 1.73 \tValidation Loss: 1.16\n",
      "Epoch: 6 \tBatch: 1 \tTraining Loss: 1.69\n",
      "Epoch: 6 \tBatch: 11 \tTraining Loss: 1.65\n",
      "Epoch: 6 \tBatch: 21 \tTraining Loss: 1.70\n",
      "Epoch: 6 \tBatch: 31 \tTraining Loss: 1.70\n",
      "Epoch: 6 \tBatch: 41 \tTraining Loss: 1.71\n",
      "Epoch: 6 \tBatch: 51 \tTraining Loss: 1.70\n",
      "Epoch: 6 \tBatch: 61 \tTraining Loss: 1.71\n",
      "Accuracy of the network on the 1533 validation images: 64.9706457925636 %\n",
      "Epoch: 6 \tTraining Loss: 1.71 \tValidation Loss: 1.15\n",
      "Epoch: 7 \tBatch: 1 \tTraining Loss: 1.61\n",
      "Epoch: 7 \tBatch: 11 \tTraining Loss: 1.70\n",
      "Epoch: 7 \tBatch: 21 \tTraining Loss: 1.68\n",
      "Epoch: 7 \tBatch: 31 \tTraining Loss: 1.68\n",
      "Epoch: 7 \tBatch: 41 \tTraining Loss: 1.69\n",
      "Epoch: 7 \tBatch: 51 \tTraining Loss: 1.70\n",
      "Epoch: 7 \tBatch: 61 \tTraining Loss: 1.70\n",
      "Accuracy of the network on the 1533 validation images: 64.77495107632095 %\n",
      "Epoch: 7 \tTraining Loss: 1.70 \tValidation Loss: 1.15\n",
      "Epoch: 8 \tBatch: 1 \tTraining Loss: 1.61\n",
      "Epoch: 8 \tBatch: 11 \tTraining Loss: 1.67\n",
      "Epoch: 8 \tBatch: 21 \tTraining Loss: 1.70\n",
      "Epoch: 8 \tBatch: 31 \tTraining Loss: 1.70\n",
      "Epoch: 8 \tBatch: 41 \tTraining Loss: 1.71\n",
      "Epoch: 8 \tBatch: 51 \tTraining Loss: 1.70\n",
      "Epoch: 8 \tBatch: 61 \tTraining Loss: 1.70\n",
      "Accuracy of the network on the 1533 validation images: 64.38356164383562 %\n",
      "Epoch: 8 \tTraining Loss: 1.70 \tValidation Loss: 1.14\n",
      "Epoch: 9 \tBatch: 1 \tTraining Loss: 1.79\n",
      "Epoch: 9 \tBatch: 11 \tTraining Loss: 1.71\n",
      "Epoch: 9 \tBatch: 21 \tTraining Loss: 1.72\n",
      "Epoch: 9 \tBatch: 31 \tTraining Loss: 1.72\n",
      "Epoch: 9 \tBatch: 41 \tTraining Loss: 1.73\n",
      "Epoch: 9 \tBatch: 51 \tTraining Loss: 1.71\n",
      "Epoch: 9 \tBatch: 61 \tTraining Loss: 1.72\n",
      "Accuracy of the network on the 1533 validation images: 64.9706457925636 %\n",
      "Epoch: 9 \tTraining Loss: 1.73 \tValidation Loss: 1.14\n",
      "Epoch: 10 \tBatch: 1 \tTraining Loss: 1.76\n",
      "Epoch: 10 \tBatch: 11 \tTraining Loss: 1.71\n",
      "Epoch: 10 \tBatch: 21 \tTraining Loss: 1.72\n",
      "Epoch: 10 \tBatch: 31 \tTraining Loss: 1.72\n",
      "Epoch: 10 \tBatch: 41 \tTraining Loss: 1.70\n",
      "Epoch: 10 \tBatch: 51 \tTraining Loss: 1.70\n",
      "Epoch: 10 \tBatch: 61 \tTraining Loss: 1.70\n",
      "Accuracy of the network on the 1533 validation images: 64.31833007175473 %\n",
      "Epoch: 10 \tTraining Loss: 1.71 \tValidation Loss: 1.13\n",
      "Epoch: 11 \tBatch: 1 \tTraining Loss: 1.63\n",
      "Epoch: 11 \tBatch: 11 \tTraining Loss: 1.65\n",
      "Epoch: 11 \tBatch: 21 \tTraining Loss: 1.67\n",
      "Epoch: 11 \tBatch: 31 \tTraining Loss: 1.67\n",
      "Epoch: 11 \tBatch: 41 \tTraining Loss: 1.68\n",
      "Epoch: 11 \tBatch: 51 \tTraining Loss: 1.69\n",
      "Epoch: 11 \tBatch: 61 \tTraining Loss: 1.69\n",
      "Accuracy of the network on the 1533 validation images: 64.84018264840182 %\n",
      "Epoch: 11 \tTraining Loss: 1.69 \tValidation Loss: 1.12\n",
      "Epoch: 12 \tBatch: 1 \tTraining Loss: 1.56\n",
      "Epoch: 12 \tBatch: 11 \tTraining Loss: 1.69\n",
      "Epoch: 12 \tBatch: 21 \tTraining Loss: 1.65\n",
      "Epoch: 12 \tBatch: 31 \tTraining Loss: 1.66\n",
      "Epoch: 12 \tBatch: 41 \tTraining Loss: 1.66\n",
      "Epoch: 12 \tBatch: 51 \tTraining Loss: 1.66\n",
      "Epoch: 12 \tBatch: 61 \tTraining Loss: 1.66\n",
      "Accuracy of the network on the 1533 validation images: 64.70971950424006 %\n",
      "Epoch: 12 \tTraining Loss: 1.66 \tValidation Loss: 1.12\n",
      "Epoch: 13 \tBatch: 1 \tTraining Loss: 1.85\n",
      "Epoch: 13 \tBatch: 11 \tTraining Loss: 1.67\n",
      "Epoch: 13 \tBatch: 21 \tTraining Loss: 1.70\n",
      "Epoch: 13 \tBatch: 31 \tTraining Loss: 1.68\n",
      "Epoch: 13 \tBatch: 41 \tTraining Loss: 1.67\n",
      "Epoch: 13 \tBatch: 51 \tTraining Loss: 1.68\n",
      "Epoch: 13 \tBatch: 61 \tTraining Loss: 1.68\n",
      "Accuracy of the network on the 1533 validation images: 65.10110893672538 %\n",
      "Epoch: 13 \tTraining Loss: 1.69 \tValidation Loss: 1.11\n",
      "Epoch: 14 \tBatch: 1 \tTraining Loss: 1.51\n",
      "Epoch: 14 \tBatch: 11 \tTraining Loss: 1.68\n",
      "Epoch: 14 \tBatch: 21 \tTraining Loss: 1.67\n",
      "Epoch: 14 \tBatch: 31 \tTraining Loss: 1.65\n",
      "Epoch: 14 \tBatch: 41 \tTraining Loss: 1.66\n",
      "Epoch: 14 \tBatch: 51 \tTraining Loss: 1.67\n",
      "Epoch: 14 \tBatch: 61 \tTraining Loss: 1.67\n",
      "Accuracy of the network on the 1533 validation images: 65.55772994129158 %\n",
      "Epoch: 14 \tTraining Loss: 1.67 \tValidation Loss: 1.10\n",
      "Epoch: 15 \tBatch: 1 \tTraining Loss: 1.63\n",
      "Epoch: 15 \tBatch: 11 \tTraining Loss: 1.67\n",
      "Epoch: 15 \tBatch: 21 \tTraining Loss: 1.66\n",
      "Epoch: 15 \tBatch: 31 \tTraining Loss: 1.64\n",
      "Epoch: 15 \tBatch: 41 \tTraining Loss: 1.65\n",
      "Epoch: 15 \tBatch: 51 \tTraining Loss: 1.65\n",
      "Epoch: 15 \tBatch: 61 \tTraining Loss: 1.66\n",
      "Accuracy of the network on the 1533 validation images: 65.68819308545336 %\n",
      "Epoch: 15 \tTraining Loss: 1.67 \tValidation Loss: 1.10\n",
      "Epoch: 16 \tBatch: 1 \tTraining Loss: 1.72\n",
      "Epoch: 16 \tBatch: 11 \tTraining Loss: 1.67\n",
      "Epoch: 16 \tBatch: 21 \tTraining Loss: 1.64\n",
      "Epoch: 16 \tBatch: 31 \tTraining Loss: 1.65\n",
      "Epoch: 16 \tBatch: 41 \tTraining Loss: 1.66\n",
      "Epoch: 16 \tBatch: 51 \tTraining Loss: 1.65\n",
      "Epoch: 16 \tBatch: 61 \tTraining Loss: 1.65\n",
      "Accuracy of the network on the 1533 validation images: 66.07958251793868 %\n",
      "Epoch: 16 \tTraining Loss: 1.66 \tValidation Loss: 1.09\n",
      "Epoch: 17 \tBatch: 1 \tTraining Loss: 1.46\n",
      "Epoch: 17 \tBatch: 11 \tTraining Loss: 1.62\n",
      "Epoch: 17 \tBatch: 21 \tTraining Loss: 1.60\n",
      "Epoch: 17 \tBatch: 31 \tTraining Loss: 1.61\n",
      "Epoch: 17 \tBatch: 41 \tTraining Loss: 1.59\n",
      "Epoch: 17 \tBatch: 51 \tTraining Loss: 1.60\n",
      "Epoch: 17 \tBatch: 61 \tTraining Loss: 1.60\n",
      "Accuracy of the network on the 1533 validation images: 64.70971950424006 %\n",
      "Epoch: 17 \tTraining Loss: 1.61 \tValidation Loss: 1.09\n",
      "Epoch: 18 \tBatch: 1 \tTraining Loss: 1.57\n",
      "Epoch: 18 \tBatch: 11 \tTraining Loss: 1.63\n",
      "Epoch: 18 \tBatch: 21 \tTraining Loss: 1.62\n",
      "Epoch: 18 \tBatch: 31 \tTraining Loss: 1.62\n",
      "Epoch: 18 \tBatch: 41 \tTraining Loss: 1.64\n",
      "Epoch: 18 \tBatch: 51 \tTraining Loss: 1.63\n",
      "Epoch: 18 \tBatch: 61 \tTraining Loss: 1.63\n",
      "Accuracy of the network on the 1533 validation images: 66.14481409001957 %\n",
      "Epoch: 18 \tTraining Loss: 1.63 \tValidation Loss: 1.09\n",
      "Epoch: 19 \tBatch: 1 \tTraining Loss: 1.49\n",
      "Epoch: 19 \tBatch: 11 \tTraining Loss: 1.58\n",
      "Epoch: 19 \tBatch: 21 \tTraining Loss: 1.64\n",
      "Epoch: 19 \tBatch: 31 \tTraining Loss: 1.62\n",
      "Epoch: 19 \tBatch: 41 \tTraining Loss: 1.63\n",
      "Epoch: 19 \tBatch: 51 \tTraining Loss: 1.62\n",
      "Epoch: 19 \tBatch: 61 \tTraining Loss: 1.63\n",
      "Accuracy of the network on the 1533 validation images: 64.84018264840182 %\n",
      "Epoch: 19 \tTraining Loss: 1.63 \tValidation Loss: 1.08\n",
      "Epoch: 20 \tBatch: 1 \tTraining Loss: 1.52\n",
      "Epoch: 20 \tBatch: 11 \tTraining Loss: 1.59\n",
      "Epoch: 20 \tBatch: 21 \tTraining Loss: 1.63\n",
      "Epoch: 20 \tBatch: 31 \tTraining Loss: 1.63\n",
      "Epoch: 20 \tBatch: 41 \tTraining Loss: 1.62\n",
      "Epoch: 20 \tBatch: 51 \tTraining Loss: 1.62\n",
      "Epoch: 20 \tBatch: 61 \tTraining Loss: 1.62\n",
      "Accuracy of the network on the 1533 validation images: 65.68819308545336 %\n",
      "Epoch: 20 \tTraining Loss: 1.63 \tValidation Loss: 1.08\n"
     ]
    }
   ],
   "source": [
    "output_model =  train(20, dataloaders, efficientnet, optimizer, loss_function, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4b. Evaluate both models on a withheld test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T19:12:56.239995Z",
     "iopub.status.busy": "2023-04-29T19:12:56.239596Z",
     "iopub.status.idle": "2023-04-29T19:13:09.379719Z",
     "shell.execute_reply": "2023-04-29T19:13:09.378761Z",
     "shell.execute_reply.started": "2023-04-29T19:12:56.239948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2172 testing images:  74.54 %\n"
     ]
    }
   ],
   "source": [
    "redirect_error()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "final_predictions = []\n",
    "final_labels = []\n",
    "\n",
    "f = []\n",
    "for images, labels in dataloaders['test']:\n",
    "    if use_cuda:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = efficientnet(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    \n",
    "    final_predictions.extend(predicted.tolist())\n",
    "    final_labels.extend(labels.tolist())\n",
    "    \n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "print(f'Accuracy of the network on the {total} testing images: {100 * correct / total: .2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T07:42:04.610038Z",
     "iopub.status.busy": "2023-04-29T07:42:04.608931Z",
     "iopub.status.idle": "2023-04-29T07:42:04.617889Z",
     "shell.execute_reply": "2023-04-29T07:42:04.616890Z",
     "shell.execute_reply.started": "2023-04-29T07:42:04.609962Z"
    }
   },
   "source": [
    "## These are the metrics that we are getting for 70 Epochs. If we run for more epochs then we might get better results. We can experiment different values of hyperparameters as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T19:13:09.382459Z",
     "iopub.status.busy": "2023-04-29T19:13:09.381183Z",
     "iopub.status.idle": "2023-04-29T19:13:09.406412Z",
     "shell.execute_reply": "2023-04-29T19:13:09.405809Z",
     "shell.execute_reply.started": "2023-04-29T19:13:09.382423Z"
    }
   },
   "outputs": [],
   "source": [
    "acc_score = accuracy_score(final_labels, final_predictions)\n",
    "precision = precision_score(final_labels, final_predictions, average='macro')\n",
    "recall = recall_score(final_labels, final_predictions, average='macro')\n",
    "f1 = f1_score(final_labels, final_predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T19:13:09.408551Z",
     "iopub.status.busy": "2023-04-29T19:13:09.408145Z",
     "iopub.status.idle": "2023-04-29T19:13:09.417231Z",
     "shell.execute_reply": "2023-04-29T19:13:09.416380Z",
     "shell.execute_reply.started": "2023-04-29T19:13:09.408511Z"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(final_labels, final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T19:13:09.419622Z",
     "iopub.status.busy": "2023-04-29T19:13:09.419092Z",
     "iopub.status.idle": "2023-04-29T19:13:09.426238Z",
     "shell.execute_reply": "2023-04-29T19:13:09.425366Z",
     "shell.execute_reply.started": "2023-04-29T19:13:09.419562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0, 25,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0, 12, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 17,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  9,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0, 11]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing confusion matrix is difficult because we have 120 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5B. Display results on the test set for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T19:13:09.428959Z",
     "iopub.status.busy": "2023-04-29T19:13:09.428093Z",
     "iopub.status.idle": "2023-04-29T19:13:09.449970Z",
     "shell.execute_reply": "2023-04-29T19:13:09.449157Z",
     "shell.execute_reply.started": "2023-04-29T19:13:09.428913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('              precision    recall  f1-score   support\\n'\n",
      " '\\n'\n",
      " '           0       0.80      0.67      0.73        18\\n'\n",
      " '           1       0.78      0.86      0.82        29\\n'\n",
      " '           2       0.71      0.92      0.80        13\\n'\n",
      " '           3       0.71      0.68      0.70        22\\n'\n",
      " '           4       0.62      0.29      0.40        17\\n'\n",
      " '           5       0.71      0.60      0.65        20\\n'\n",
      " '           6       0.62      0.71      0.67        21\\n'\n",
      " '           7       0.68      0.90      0.78        21\\n'\n",
      " '           8       0.62      0.72      0.67        18\\n'\n",
      " '           9       0.74      0.74      0.74        19\\n'\n",
      " '          10       0.86      0.86      0.86        22\\n'\n",
      " '          11       0.81      0.86      0.83        29\\n'\n",
      " '          12       0.68      0.68      0.68        19\\n'\n",
      " '          13       0.90      0.95      0.92        19\\n'\n",
      " '          14       0.67      0.82      0.74        17\\n'\n",
      " '          15       0.75      0.68      0.71        22\\n'\n",
      " '          16       0.68      0.79      0.73        19\\n'\n",
      " '          17       0.81      0.85      0.83        20\\n'\n",
      " '          18       0.86      0.57      0.69        21\\n'\n",
      " '          19       0.75      0.83      0.79        18\\n'\n",
      " '          20       0.54      0.78      0.64         9\\n'\n",
      " '          21       0.80      0.47      0.59        17\\n'\n",
      " '          22       0.87      0.93      0.90        14\\n'\n",
      " '          23       0.89      0.53      0.67        15\\n'\n",
      " '          24       0.88      0.67      0.76        21\\n'\n",
      " '          25       0.82      0.93      0.87        15\\n'\n",
      " '          26       0.74      0.58      0.65        24\\n'\n",
      " '          27       0.71      0.67      0.69        15\\n'\n",
      " '          28       0.88      0.78      0.82        18\\n'\n",
      " '          29       0.58      0.54      0.56        13\\n'\n",
      " '          30       1.00      0.94      0.97        18\\n'\n",
      " '          31       0.94      0.94      0.94        18\\n'\n",
      " '          32       0.80      0.71      0.75        17\\n'\n",
      " '          33       0.46      0.40      0.43        15\\n'\n",
      " '          34       0.82      0.88      0.85        16\\n'\n",
      " '          35       0.84      0.94      0.89        17\\n'\n",
      " '          36       0.87      0.95      0.91        21\\n'\n",
      " '          37       0.75      0.69      0.72        13\\n'\n",
      " '          38       0.60      0.69      0.64        13\\n'\n",
      " '          39       0.94      0.76      0.84        21\\n'\n",
      " '          40       0.74      0.70      0.72        20\\n'\n",
      " '          41       0.74      0.93      0.82        15\\n'\n",
      " '          42       0.64      0.86      0.73        21\\n'\n",
      " '          43       0.00      0.00      0.00        14\\n'\n",
      " '          44       0.65      0.79      0.71        19\\n'\n",
      " '          45       0.79      0.79      0.79        19\\n'\n",
      " '          46       1.00      0.62      0.76        13\\n'\n",
      " '          47       0.81      0.81      0.81        16\\n'\n",
      " '          48       0.69      0.53      0.60        17\\n'\n",
      " '          49       0.82      0.69      0.75        13\\n'\n",
      " '          50       0.62      0.91      0.74        11\\n'\n",
      " '          51       0.64      0.58      0.61        12\\n'\n",
      " '          52       0.56      0.88      0.68        16\\n'\n",
      " '          53       0.79      0.71      0.75        21\\n'\n",
      " '          54       0.93      0.78      0.85        18\\n'\n",
      " '          55       0.93      0.59      0.72        22\\n'\n",
      " '          56       0.93      0.78      0.85        18\\n'\n",
      " '          57       0.82      0.78      0.80        18\\n'\n",
      " '          58       0.72      0.72      0.72        18\\n'\n",
      " '          59       0.43      0.71      0.53        17\\n'\n",
      " '          60       0.40      0.62      0.48        13\\n'\n",
      " '          61       0.86      0.93      0.89        27\\n'\n",
      " '          62       0.94      1.00      0.97        17\\n'\n",
      " '          63       0.86      0.67      0.75        18\\n'\n",
      " '          64       0.89      0.85      0.87        20\\n'\n",
      " '          65       0.93      0.93      0.93        14\\n'\n",
      " '          66       1.00      0.63      0.77        19\\n'\n",
      " '          67       0.70      0.70      0.70        20\\n'\n",
      " '          68       0.32      0.47      0.38        15\\n'\n",
      " '          69       0.81      1.00      0.89        17\\n'\n",
      " '          70       0.60      0.56      0.58        16\\n'\n",
      " '          71       0.58      0.71      0.64        21\\n'\n",
      " '          72       0.86      0.80      0.83        15\\n'\n",
      " '          73       0.64      0.95      0.77        19\\n'\n",
      " '          74       0.95      0.95      0.95        21\\n'\n",
      " '          75       0.80      0.83      0.82        24\\n'\n",
      " '          76       0.50      0.57      0.53        14\\n'\n",
      " '          77       0.62      0.89      0.73        18\\n'\n",
      " '          78       0.81      0.74      0.77        23\\n'\n",
      " '          79       0.80      0.67      0.73        18\\n'\n",
      " '          80       1.00      0.90      0.95        20\\n'\n",
      " '          81       0.72      0.76      0.74        17\\n'\n",
      " '          82       0.93      0.82      0.87        17\\n'\n",
      " '          83       1.00      0.58      0.74        12\\n'\n",
      " '          84       0.84      1.00      0.91        21\\n'\n",
      " '          85       0.93      0.78      0.85        18\\n'\n",
      " '          86       0.75      1.00      0.86        21\\n'\n",
      " '          87       0.88      0.88      0.88        25\\n'\n",
      " '          88       0.77      0.77      0.77        22\\n'\n",
      " '          89       0.71      0.67      0.69        15\\n'\n",
      " '          90       0.41      0.81      0.54        16\\n'\n",
      " '          91       0.67      0.57      0.62        14\\n'\n",
      " '          92       0.89      0.85      0.87        20\\n'\n",
      " '          93       0.71      0.71      0.71        24\\n'\n",
      " '          94       0.93      0.87      0.90        15\\n'\n",
      " '          95       0.69      0.79      0.73        14\\n'\n",
      " '          96       0.65      0.94      0.77        16\\n'\n",
      " '          97       0.85      0.76      0.80        29\\n'\n",
      " '          98       0.85      0.85      0.85        13\\n'\n",
      " '          99       0.79      0.58      0.67        19\\n'\n",
      " '         100       0.71      0.63      0.67        27\\n'\n",
      " '         101       0.48      0.70      0.57        20\\n'\n",
      " '         102       0.62      0.68      0.65        22\\n'\n",
      " '         103       0.75      0.50      0.60        12\\n'\n",
      " '         104       0.59      0.70      0.64        23\\n'\n",
      " '         105       0.64      0.64      0.64        11\\n'\n",
      " '         106       0.88      0.37      0.52        19\\n'\n",
      " '         107       0.78      1.00      0.88        14\\n'\n",
      " '         108       0.93      0.61      0.74        23\\n'\n",
      " '         109       0.76      0.67      0.71        24\\n'\n",
      " '         110       0.62      0.33      0.43        15\\n'\n",
      " '         111       0.83      0.88      0.86        17\\n'\n",
      " '         112       0.76      0.62      0.68        21\\n'\n",
      " '         113       0.46      0.60      0.52        10\\n'\n",
      " '         114       0.94      1.00      0.97        15\\n'\n",
      " '         115       0.89      0.89      0.89        19\\n'\n",
      " '         116       0.77      0.83      0.80        12\\n'\n",
      " '         117       0.65      0.68      0.67        25\\n'\n",
      " '         118       0.75      0.56      0.64        16\\n'\n",
      " '         119       0.69      0.61      0.65        18\\n'\n",
      " '\\n'\n",
      " '    accuracy                           0.75      2172\\n'\n",
      " '   macro avg       0.75      0.74      0.74      2172\\n'\n",
      " 'weighted avg       0.76      0.75      0.74      2172\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(classification_report(final_labels, final_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T19:13:09.451995Z",
     "iopub.status.busy": "2023-04-29T19:13:09.451603Z",
     "iopub.status.idle": "2023-04-29T19:13:09.456771Z",
     "shell.execute_reply": "2023-04-29T19:13:09.455882Z",
     "shell.execute_reply.started": "2023-04-29T19:13:09.451955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75, Precision: 0.75, Recall: 0.74, F1-Score: 0.74\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {acc_score:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's save the model and use it in the android app since this is the best performing model so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T19:21:43.088610Z",
     "iopub.status.busy": "2023-04-29T19:21:43.088025Z",
     "iopub.status.idle": "2023-04-29T19:21:43.153267Z",
     "shell.execute_reply": "2023-04-29T19:21:43.152482Z",
     "shell.execute_reply.started": "2023-04-29T19:21:43.088567Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(efficientnet.state_dict(), 'efficientnet_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T19:30:45.182075Z",
     "iopub.status.busy": "2023-04-29T19:30:45.181432Z",
     "iopub.status.idle": "2023-04-29T19:30:45.259818Z",
     "shell.execute_reply": "2023-04-29T19:30:45.259067Z",
     "shell.execute_reply.started": "2023-04-29T19:30:45.182036Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's also save the full model incase we require it later.\n",
    "torch.save(efficientnet, 'efficientnet_model_full.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
